<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[记 JavaMelody 间接导致线上服务占用内存过高的问题排查过程]]></title>
    <url>%2F2019%2F07%2F21%2Fhole-1%2F</url>
    <content type="text"><![CDATA[一、前言经过几个月的奋战，重构终于落下帷幕，并与5月底提前上线。同时我们为每个服务配上了 JavaMelody 用于监控应用实际使用情况。 二、初见端倪然而上线几天后发现线上某个服务经常 OOM。为了尽快恢复线上使用，暂时先将 JVM 内存调高，由之前的 1G 改为 2G。于此同时分析堆 dump 文件查找具体原因，结果发现内存中有很多长 SQL。立即找到相应开发优化该 SQL，但重新部署后发现线上服务内存占用情况并未变化。理论上 300~400M 就足够了却占用了将近 1G 内存。黑人问号脸… 三、解决过程因为同一台服务器的其他服务均未出现内存占用异常的情况，所以判断应该是 Tomcat 或者是 JVM 配置的问题。 ① 首先让运维同学排查 JVM 配置与其他服务是否不同。发现除了有一个无效配置，其他均正常且该无效配置对内存并无影响。 ② 排除 JVM 的配置问题，那就聚焦到 Tomcat。于是就让运维同学将该 Tomcat 拷贝到一个空闲服务器上部署，拷贝过程中突然发现有很多前缀为 sql 的文件一闪而过，当时就引起了我们的注意。拷贝完成后我们定位到那些文件在 Tomcat 的 temp/javamelody 目录中。直觉告诉我们，应该就是这些 rrd 文件引起的，统计了一下个数，大概有两千多个。 ③ 清理所有 sql.rrd 临时文件并重启服务，发现内存占用降低到三百多兆。 ④ 分析新的堆 dump 文件，之前那堆长 SQL 也已消失。 四、总结我们知道 JavaMelody 会把项目的运行情况持久化到 rrd 文件中，上述的 sql.rrd 临时文件应该是由于长 SQL 触发了 JavaMelody 的某个机制才被持久化起来做数据分析，并且在项目部署时加载到内存中，才导致内存占用过高的问题。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>踩过的坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 项目实战（六）集成 Apollo]]></title>
    <url>%2F2019%2F04%2F06%2Fspringboot-6%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了 Spring Boot 集成 Dubbo，使我们的系统打下了分布式的基础。随着程序功能的日益复杂，程序的配置日益增多：各种功能开关、参数配置、服务器地址等；对程序配置的期望值也越来越高：配置修改后实时生效，灰度发布，分环境、分集群管理配置，完善的权限、审核机制等；在这样的大环境下，传统的通过配置文件、数据库等方式已经越来越无法满足开发人员对配置管理的需求。分布式配置中心应运而生。本篇将主要介绍分布式配置中心 Apollo 的集成过程。 二、部署 Apollo① 部署教程见官方文档：https://github.com/ctripcorp/apollo/wiki/分布式部署指南 ② 架构剖析：https://mp.weixin.qq.com/s/-hUaQPzfsl9Lm3IqQW3VDQ 三、使用 Apollo① 登录 Apollo 管理控制台后创建项目，其中应用 ID 全局唯一。② 创建成功后跳转到项目维护界面，左侧上方为环境列表，中间区域为项目信息，下方可操作集群及 namespace 。右侧为默认 namespace ：application ，具体配置项在此区域维护。 四、Spring Boot 集成 Apollo4.1 引入 Apollo 依赖包① 首先在项目父 pom 文件中声明 Apollo 依赖。12345678910&lt;dependencyManagement&gt; &lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;com.ctrip.framework.apollo&lt;/groupId&gt; &lt;artifactId&gt;apollo-client&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; ② 其次在 demo-biz 层中的 pom 文件添加上述 Apollo 依赖。1234567&lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;com.ctrip.framework.apollo&lt;/groupId&gt; &lt;artifactId&gt;apollo-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 4.2 添加 Apollo 配置项① 在 application.properties 文件中的添加 Apollo 相关的配置项：12345678910# 应用全局唯一的身份标识app.id = 20000# Apollo Meta Server 地址apollo.meta = http://xxx.xxx.xxx.xxx:7881# 自定义本地配置文件缓存路径apollo.cacheDir = ./config# 设置在应用启动阶段就加载 Apollo 配置apollo.bootstrap.enabled = true# 注入 application namespaceapollo.bootstrap.namespaces = application ② 将 application.properties 文件中的除了 Apollo 及 Logback 的其他配置项都转移到 Apollo 控制台中维护。 4.3 验证 Apollo① 启动日志中可以看到 Apollo 从 Meta Server 拉取配置项，并缓存到本地 config 目录。② 访问 http://localhost:8080/demo/test?id=1 接口正常返回。 4.4 托管 Logback 配置项① Apollo 1.2.0 版本后支持托管日志相关配置项，只需要在 application.properties 文件中增加以下 Apollo 配置项。12# 将 Apollo 配置加载提到初始化日志系统之前，需要托管日志配置时开启apollo.bootstrap.eagerLoad.enabled = true ② 将 Logback 配置项转移到 Apollo 控制台中维护。 4.5 本地开发模式某些情况下比如 Dubbo 接口本地联调，需要修改依赖方的接口版本，此时可以开启本地开发模式，在本地开发模式下，Apollo 只会从本地文件读取配置信息，不会从 Apollo 服务器读取配置。通过设置 JVM 参数开启。 4.6 Dubbo 及 Apollo 的兼容问题官方在集成 Dubbo 及 Apollo 时提供了两种方式： ① 纯 Spring Boot 方式；即依赖 dubbo-spring-boot-starter 包。 ② 原生 Dubbo 方式；即依赖 dubbo 、zookeeper 、 zkclient 、curator-framework 包，然后通过 XML 方式配置，配置项用 ${} 占位符。 而我当时为了能清楚知道，对外提供了哪些 Dubbo 接口以及依赖了哪些外部 Dubbo 接口，使用 Spring XML 的形式配置 Dubbo，同时又依赖了 dubbo-spring-boot-starter 包，结果将 Dubbo 配置项托管至 Apollo 后，出现无法找到 Dubbo 配置项的情况。原因是通过 Spring XML 方式配置 Dubbo 时所依赖的 OverrideDubboConfigApplicationListener 执行时机太早了（远早于 Apollo 配置加载的时机）。Apollo 1.2.0 版本支持「 apollo.bootstrap.eagerLoad.enabled 」配置项后虽然能解决这个问题，但还是不推荐 dubbo-spring-boot-starter + XML 这种形式的配置方式，推荐纯 Spring Boot 方式。 注：详见 https://github.com/ctripcorp/apollo/issues/1600 五、结语至此 Spring Boot 集成 Apollo 的过程介绍完毕，相关代码已同步至 GitHub 。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发规约（一）接口统一返回值格式]]></title>
    <url>%2F2019%2F03%2F18%2Fspecification-1%2F</url>
    <content type="text"><![CDATA[一、前言上篇在介绍 Spring Boot 集成 Dubbo 时，埋下了有关返回值格式的一个小小伏笔。本篇将主要介绍一种常用的返回值格式以及详细说明。 二、Dubbo 接口统一返回值格式我们在应用中经常会涉及到 server 和 client 的交互，目前比较流行的是基于 json 格式的数据交互。但是 json 只是消息的格式，其中的内容还需要我们自行设计。不管是 HTTP 接口还是 RPC 接口保持返回值格式统一很重要，这将大大降低 client 的开发成本。 2.1 定义返回值四要素 boolean success ；是否成功。 T data ；成功时具体返回值，失败时为 null 。 Integer code ；成功时返回 0 ，失败时返回具体错误码。 String message ；成功时返回 null ，失败时返回具体错误消息。 2.2 定义错误码为了兼容多种类型的错误码，可以通过声明接口的方式解决，再由具体的业务错误码类实现该接口。① 首先在 demo-common 层的 com.example.demo.common 包中添加 error 目录并新建 ServiceErrors 错误码接口类。12345678910111213141516171819202122package com.example.demo.common.error;/** * @author linjian * @date 2019/3/14 */public interface ServiceErrors &#123; /** * 获取错误码 * * @return Integer */ Integer getCode(); /** * 获取错误信息 * * @return String */ String getMessage();&#125; ② 其次再定义一个业务错误码枚举类实现上述接口类。1234567891011121314151617181920212223242526272829303132package com.example.demo.common.error;/** * @author linjian * @date 2019/3/14 */public enum DemoErrors implements ServiceErrors &#123; /** * 错误码 */ SYSTEM_ERROR(10000, "系统错误"), PARAM_ERROR(10001, "参数错误"), ; private Integer code; private String message; DemoErrors(Integer code, String message) &#123; this.code = code; this.message = message; &#125; @Override public Integer getCode() &#123; return code; &#125; @Override public String getMessage() &#123; return message; &#125;&#125; 2.3 定义 Result 返回包装类继续在 demo-common 层的 com.example.demo.common 包中添加 entity 目录并新建 Result 返回包装类。其中提供了 wrapSuccessfulResult 及 wrapErrorResult 方法用于接口调用成功或失败时的返回。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119package com.example.demo.common.entity;import com.example.demo.common.error.ServiceErrors;import java.io.Serializable;/** * @author linjian * @date 2019/3/14 */public class Result&lt;T&gt; implements Serializable &#123; private T data; private boolean success; private Integer code; private String message; public Result() &#123; &#125; public static &lt;T&gt; Result&lt;T&gt; wrapSuccessfulResult(T data) &#123; Result&lt;T&gt; result = new Result&lt;T&gt;(); result.data = data; result.success = true; result.code = 0; return result; &#125; public static &lt;T&gt; Result&lt;T&gt; wrapSuccessfulResult(String message, T data) &#123; Result&lt;T&gt; result = new Result&lt;T&gt;(); result.data = data; result.success = true; result.code = 0; result.message = message; return result; &#125; public static &lt;T&gt; Result&lt;T&gt; wrapErrorResult(ServiceErrors error) &#123; Result&lt;T&gt; result = new Result&lt;T&gt;(); result.success = false; result.code = error.getCode(); result.message = error.getMessage(); return result; &#125; public static &lt;T&gt; Result&lt;T&gt; wrapErrorResult(ServiceErrors error, Object... extendMsg) &#123; Result&lt;T&gt; result = new Result&lt;T&gt;(); result.success = false; result.code = error.getCode(); result.message = String.format(error.getMessage(), extendMsg); return result; &#125; public static &lt;T&gt; Result&lt;T&gt; wrapErrorResult(Integer code, String message) &#123; Result&lt;T&gt; result = new Result&lt;T&gt;(); result.success = false; result.code = code; result.message = message; return result; &#125; public T getData() &#123; return this.data; &#125; public Result&lt;T&gt; setData(T data) &#123; this.data = data; return this; &#125; public boolean isSuccess() &#123; return this.success; &#125; public Result&lt;T&gt; setSuccess(boolean success) &#123; this.success = success; return this; &#125; public Integer getCode() &#123; return this.code; &#125; public Result&lt;T&gt; setCode(Integer code) &#123; this.code = code; return this; &#125; public String getMessage() &#123; return this.message; &#125; public Result&lt;T&gt; setMessage(String message) &#123; this.message = message; return this; &#125; @Override public String toString() &#123; StringBuilder sb = new StringBuilder(); sb.append("&#123;"); sb.append("success="); sb.append(this.success); sb.append(","); sb.append("code="); sb.append(this.code); sb.append(","); sb.append("message="); sb.append(this.message); sb.append(","); sb.append("data="); sb.append(this.data); sb.append("&#125;"); return sb.toString(); &#125;&#125; 2.4 定义业务异常类在 demo-biz 层的 com.example.demo.biz 包中添加 exception 目录并新建 BizException 异常类。1234567891011121314151617181920212223242526package com.example.demo.biz.exception;import com.example.demo.common.error.ServiceErrors;/** * @author linjian * @date 2019/3/15 */public class BizException extends RuntimeException &#123; private final Integer code; public BizException(ServiceErrors errors) &#123; super(errors.getMessage()); this.code = errors.getCode(); &#125; public BizException(Integer code, String message) &#123; super(message); this.code = code; &#125; public Integer getCode() &#123; return this.code; &#125;&#125; 2.5 定义异常处理切面前面的准备工作做好之后，接下来才是真正的统一格式处理。不管是 HTTP 接口 还是 RPC 接口，在处理业务逻辑时，都可以通过抛出业务异常，再由 Spring AOP 切面捕捉并封装返回值，从而达到对外接口返回值格式统一的目的。① 首先在 demo-web 层的 pom 文件中引入 Spring AOP 的依赖包。该包已经集成在 Spring Boot 提供的父工程中，这里直接引入即可。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; ② 其次在 demo-web 层的 com.example.demo.web 包中添加 aspect 目录并新建 DubboServiceAspect 切面类。通过「拦截器」及「反射」实现将业务异常封装为 Result 返回。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.example.demo.web.aspect;import com.example.demo.biz.exception.BizException;import com.example.demo.common.entity.Result;import com.example.demo.common.error.DemoErrors;import lombok.extern.slf4j.Slf4j;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;import org.springframework.stereotype.Component;import java.lang.reflect.Method;import java.util.Arrays;/** * @author linjian * @date 2019/3/14 */@Slf4j@Componentpublic class DubboServiceAspect implements MethodInterceptor &#123; @Override public Object invoke(final MethodInvocation methodInvocation) throws Throwable &#123; try &#123; return methodInvocation.proceed(); &#125; catch (BizException e) &#123; log.error("BizException", e); return exceptionProcessor(methodInvocation, e); &#125; catch (Exception e) &#123; log.error("Exception:", e); return exceptionProcessor(methodInvocation, e); &#125; &#125; private Object exceptionProcessor(MethodInvocation methodInvocation, Exception e) &#123; Object[] args = methodInvocation.getArguments(); Method method = methodInvocation.getMethod(); String methodName = method.getDeclaringClass().getName() + "." + method.getName(); log.error("dubbo服务[method=" + methodName + "] params=" + Arrays.toString(args) + "异常：", e); Class&lt;?&gt; clazz = method.getReturnType(); if (clazz.equals(Result.class)) &#123; Result result = new Result(); result.setSuccess(false); if (e instanceof BizException) &#123; result.setCode(((BizException) e).getCode()); result.setMessage(e.getMessage()); &#125; else &#123; result.setCode(DemoErrors.SYSTEM_ERROR.getCode()); result.setMessage(DemoErrors.SYSTEM_ERROR.getMessage()); &#125; return result; &#125; return null; &#125;&#125; ③ 定义处理类之后再通过 Spring XML 的形式定义切面，在 demo-web 层的 resources 目录中新建 spring-aop.xml 文件，在其中定义 Dubbo 接口的切面。123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;aop:config&gt; &lt;aop:pointcut id="dubboRemoteServiceAspect" expression="execution(* com.example.demo.remote.service.*.*(..))"/&gt; &lt;aop:advisor advice-ref="dubboServiceAspect" pointcut-ref="remoteServiceAspect"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; ④ 继续在 demo-web 层的 resources 目录中，再新建 application-context.xml 文件统一管理所有 Spring XML 配置文件，现在先往其中导入 spring-aop.xml 文件。12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;import resource="classpath:spring-aop.xml"/&gt;&lt;/beans&gt; ⑤ 最后在 DemoWebApplication 入口类中通过 @ImportResource 注解导入 Spring 的 XML 配置文件。1@ImportResource(&#123;"classpath:application-context.xml"&#125;) 此时处理异常的切面已经配置完毕，接下来通过修改之前定义的 RpcDemoService.test 方法测试切面是否有效。 2.6 切面测试① 首先将 RpcDemoService.test 方法的返回结果用 Result 包装。1234567891011121314151617181920package com.example.demo.remote.service;import com.example.demo.common.entity.Result;import com.example.demo.remote.model.param.DemoParam;import com.example.demo.remote.model.result.DemoDTO;/** * @author linjian * @date 2019/3/15 */public interface RpcDemoService &#123; /** * Dubbo 接口测试 * * @param param DemoParam * @return DemoDTO */ Result&lt;DemoDTO&gt; test(DemoParam param);&#125; 123456789101112131415161718192021222324252627package com.example.demo.biz.service.impl.remote;import com.alibaba.dubbo.config.annotation.Service;import com.example.demo.biz.service.DemoService;import com.example.demo.common.entity.Result;import com.example.demo.remote.model.param.DemoParam;import com.example.demo.remote.model.result.DemoDTO;import com.example.demo.remote.service.RpcDemoService;import org.springframework.beans.factory.annotation.Autowired;/** * @author linjian * @date 2019/3/15 */@Servicepublic class RpcDemoServiceImpl implements RpcDemoService &#123; @Autowired private DemoService demoService; @Override public Result&lt;DemoDTO&gt; test(DemoParam param) &#123; DemoDTO demo = new DemoDTO(); demo.setStr(demoService.test(param.getId())); return Result.wrapSuccessfulResult(demo); &#125;&#125; ② 再修改 DemoService.test 方法的内部逻辑，查询数据库后先判断是否有数据，没有的话抛出一个业务异常。123456789101112131415161718192021222324252627282930313233package com.example.demo.biz.service.impl;import com.example.demo.biz.exception.BizException;import com.example.demo.biz.service.DemoService;import com.example.demo.common.error.DemoErrors;import com.example.demo.dao.entity.UserDO;import com.example.demo.dao.mapper.business.UserMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.util.Assert;import java.util.Objects;/** * @author linjian * @date 2019/1/15 */@Servicepublic class DemoServiceImpl implements DemoService &#123; @Autowired private UserMapper userMapper; @Override public String test(Integer id) &#123; Assert.notNull(id, "id不能为空"); UserDO user = userMapper.selectById(id); if (Objects.isNull(user)) &#123; throw new BizException(DemoErrors.USER_IS_NOT_EXIST); &#125; return user.toString(); &#125;&#125; ③ 然后 cd 到 demo-remote 目录，执行 mvn deploy 命令重新打包。此时服务提供者的调整工作已结束，接下来通过测试项目看效果。④ 来到测试项目，调整中的 TestController.test 方法，增加 id 传参。123456789101112131415161718192021222324252627282930package com.yibao.dawn.web.controller;import com.alibaba.dubbo.config.annotation.Reference;import com.example.demo.common.entity.Result;import com.example.demo.remote.model.param.DemoParam;import com.example.demo.remote.model.result.DemoDTO;import com.example.demo.remote.service.RpcDemoService;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;/** * @author linjian * @date 2019/3/7 */@RestController@RequestMapping("test")public class TestController &#123; @Reference(version = "1.0.0.dev") private RpcDemoService rpcDemoService; @GetMapping("dubbo") public Result&lt;DemoDTO&gt; test(@RequestParam("id") Integer id) &#123; DemoParam param = new DemoParam(); param.setId(id); return rpcDemoService.test(param); &#125;&#125; ⑤ 测试在传参 id = 1 及 id = 2 的情况下，分别有如下返回结果：因为此时数据库中只有 id = 1 的一条数据，当传参 id = 2 时就触发了 DemoErrors.USER_IS_NOT_EXIST 的业务异常。 三、HTTP 接口统一返回值格式3.1 定义切面处理类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.example.demo.web.aspect;import com.example.demo.biz.exception.BizException;import com.example.demo.common.entity.Result;import com.example.demo.common.error.DemoErrors;import lombok.extern.slf4j.Slf4j;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;import org.springframework.stereotype.Component;/** * @author linjian * @date 2018/9/26 */@Slf4j@Componentpublic class HttpServiceAspect implements MethodInterceptor &#123; @Override public Result invoke(final MethodInvocation methodInvocation) throws Throwable &#123; Result result = new Result(); try &#123; String methodName = methodInvocation.getMethod().getName(); if (log.isDebugEnabled()) &#123; log.debug("starting business logic processing.... " + methodName); &#125; result = (Result) methodInvocation.proceed(); if (log.isDebugEnabled()) &#123; log.debug("finished business logic processing...." + methodName); &#125; &#125; catch (BizException e) &#123; result.setSuccess(false); result.setCode(e.getCode()); result.setMessage(e.getMessage()); &#125; catch (IllegalArgumentException e) &#123; result.setSuccess(false); result.setCode(DemoErrors.PARAM_ERROR.getCode()); result.setMessage(e.getMessage()); &#125; catch (RuntimeException e) &#123; log.error("系统出错", e); result.setSuccess(false); result.setCode(DemoErrors.SYSTEM_ERROR.getCode()); result.setMessage(DemoErrors.SYSTEM_ERROR.getMessage()); &#125; return result; &#125;&#125; 3.2 定义切面在 spring-aop.xml 文件中追加一个切面定义。123456&lt;aop:config&gt; &lt;aop:pointcut id="resultControllerAspect" expression="@within(org.springframework.web.bind.annotation.RestController) and execution(com.example.demo.common.entity.Result *.*(..))"/&gt; &lt;aop:advisor advice-ref="httpServiceAspect" pointcut-ref="resultControllerAspect"/&gt;&lt;/aop:config&gt; 四、结语至此接口统一返回值格式的方法介绍完毕，如果公司内部项目多了，可以将一些公用的组件提取出来单独作为一个项目打成二方包供其他项目依赖，保持内部项目的统一。 注：相关代码已同步至 GitHub]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>开发规约</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 项目实战（五）集成 Dubbo]]></title>
    <url>%2F2019%2F03%2F15%2Fspringboot-5%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了 Redis 的集成过程，可用于解决热点数据访问的性能问题。随着业务复杂度的提高，单体应用越来越庞大，就好比一个类的代码行数越来越多，分而治之，切成多个类应该是更好的解决方法，所以一个庞大的单体应用分出多个小应用也更符合这种分治的思想。于是乎微服务化的概念油然而生，微服务化的第一步就是选择适用的分布式服务框架，基于团队成员有使用过「 Dubbo 」的经验，我们放弃了完全陌生的「 Spring Cloud 」。本篇将主要介绍在 Spring Boot 中集成 Dubbo 的过程。 二、集成 Dubbo2.1 引入 Dubbo 依赖包① 首先在项目父 pom 文件中声明 Dubbo 依赖。12345678910&lt;dependencyManagement&gt; &lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; ② 其次在 demo-biz 层中的 pom 文件添加上述 Dubbo 依赖。1234567&lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.2 添加 Dubbo 常用配置项在 application.properties 文件中的添加 Dubbo 相关的配置项：1234567891011121314151617181920# 当前应用名称，用于注册中心计算应用间依赖关系dubbo.application.name = demo# 组织名称，用于注册中心区分服务来源dubbo.application.organization = example# 应用负责人，用于服务治理dubbo.application.owner = linjian# 注册中心地址协议dubbo.registry.protocol = zookeeper# 注册中心服务器地址dubbo.registry.address = 127.0.0.1:2181# 协议名称dubbo.protocol.name = dubbo# 服务端口dubbo.protocol.port = 20880# 服务版本dubbo.provider.version = 1.0.0.dev# 远程服务调用超时时间(毫秒)dubbo.provider.timeout = 60000# 启动时检查提供者是否存在dubbo.consumer.check = false 注：详细配置见 官方配置参考手册 三、接口服务化3.1 Dubbo 接口编程规约 Dubbo 接口类以 Rpc 为前缀命名并剥离出一个单独的模块，称之为远程服务层 请求参数类以 Param 为后缀命名并统一存放于「 param 」目录 返回结果类以 DTO 为后缀命名并统一存放于「 result 」目录 统一返回值格式，详见 开发规约（一）接口统一返回值格式3.2 创建远程服务层① 首先按照该篇博客 Spring Boot 项目实战（一）Maven 多模块项目搭建 中的「4.2 创建子模块」一节添加「 demo-remote 」子模块。② 其次在项目父 pom 文件的 dependencyManagement 标签中声明 demo-remote 子模块的依赖。12345&lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-remote&lt;/artifactId&gt; &lt;version&gt;$&#123;demo.version&#125;&lt;/version&gt;&lt;/dependency&gt; ③ 然后在 demo-biz 层中的 pom 文件中添加 demo-remote 依赖。1234567&lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-remote&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 由于 demo-remote 层最终是要打成一个 JAR 包供外部引入，而其接口的内部实现还是需要写在 demo-biz 层，所以我们将这两个模块之间建立了依赖关系，并在 demo-biz 层 com.example.demo.biz.service.impl 包中，新建 remote 目录存放 demo-remote 层远程服务接口的具体实现。④ 在 DemoWebApplication 入口类中增加 Dubbo 接口实现类包扫描，设置 @DubboComponentScan 注解中的 basePackages 值为 com.example.demo.biz.service.impl.remote1@DubboComponentScan(basePackages = "com.example.demo.biz.service.impl.remote") 3.3 简易 Dubbo 接口测试配置完模块间的依赖关系后，我们通过一个简易的 Dubbo 接口测试是否可用。① 首先在 demo-remote 层的 pom 文件中添加必要的 lombok 依赖123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ① 其次在该层创建 com.example.demo.remote 包，添加 param 目录并在其中创建 DemoParam 请求参数类，添加 result 目录并在其中创建 DemoDTO 返回结果类，添加 service 目录并在其中创建 RpcDemoService 接口类。123456789101112131415package com.example.demo.remote.model.param;import lombok.Data;import java.io.Serializable;/** * @author linjian * @date 2019/3/15 */@Datapublic class DemoParam implements Serializable &#123; private Integer id;&#125; 123456789101112131415package com.example.demo.remote.model.result;import lombok.Data;import java.io.Serializable;/** * @author linjian * @date 2019/3/15 */@Datapublic class DemoDTO implements Serializable &#123; private String str;&#125; 12345678910111213141516171819package com.example.demo.remote.service;import com.example.demo.remote.model.param.DemoParam;import com.example.demo.remote.model.result.DemoDTO;/** * @author linjian * @date 2019/3/15 */public interface RpcDemoService &#123; /** * Dubbo 接口测试 * * @param param DemoParam * @return DemoDTO */ DemoDTO test(DemoParam param);&#125; ② 在 demo-biz 层 com.example.demo.biz.service.impl.remote 包中新建 RpcDemoServiceImpl 接口实现类。1234567891011121314151617181920212223242526package com.example.demo.biz.service.impl.remote;import com.alibaba.dubbo.config.annotation.Service;import com.example.demo.biz.service.DemoService;import com.example.demo.remote.model.param.DemoParam;import com.example.demo.remote.model.result.DemoDTO;import com.example.demo.remote.service.RpcDemoService;import org.springframework.beans.factory.annotation.Autowired;/** * @author linjian * @date 2019/3/15 */@Servicepublic class RpcDemoServiceImpl implements RpcDemoService &#123; @Autowired private DemoService demoService; @Override public DemoDTO test(DemoParam param) &#123; DemoDTO demo = new DemoDTO(); demo.setStr(demoService.test()); return demo; &#125;&#125; ③ 运行 DemoWebApplication 启动类的 main 方法，查看控制台打印日志可以得到如下结果：从上图可以看出服务已经注册成功 ④ 同时通过 Dubbo Admin 管理控制台也可以看到刚注册的服务： 3.4 暴露远程服务① 在 demo-remote 层的 pom 文件中添加 distributionManagement 标签并在其中配置 Nexus 私服的 snapshot 快照库及 release 发布库。12345678910&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;yibao-releases&lt;/id&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;yibao-snapshots&lt;/id&gt; &lt;url&gt;http://127.0.0.1:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; ② cd 到 demo-remote 目录，执行 mvn deploy 命令打包，完成后可在 Nexus 私服看到刚打的依赖包。③ 搭建一个测试项目并引入 demo-remote 依赖包，新建 TestController 类测试 Dubbo 接口。 注：该测试项目也需集成 Dubbo 12345678910111213141516171819202122232425262728package com.example.dawn.web.controller;import com.alibaba.dubbo.config.annotation.Reference;import com.example.demo.remote.model.param.DemoParam;import com.example.demo.remote.model.result.DemoDTO;import com.example.demo.remote.service.RpcDemoService;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author linjian * @date 2019/3/7 */@RestController@RequestMapping("test")public class TestController &#123; @Reference(version = "1.0.0.dev") private RpcDemoService rpcDemoService; @GetMapping("dubbo") public DemoDTO test() &#123; DemoParam param = new DemoParam(); param.setId(1); return rpcDemoService.test(param); &#125;&#125; ③ 启动测试项目，观察 Dubbo Admin 管理控制台消费者一栏，可以看到测试项目已经作为一个消费者调用 RpcDemoService 接口类。④ 访问 http://localhost:8079/test/dubbo 查看接口返回结果。 四、结语至此 Spring Boot 集成 Dubbo 的过程介绍完毕，我们通过一个简易的 Dubbo 接口测试其可用性，相关代码已同步至 GitHub 。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 项目实战（四）集成 Redis]]></title>
    <url>%2F2019%2F03%2F02%2Fspringboot-4%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了接口文档工具 Swagger 及项目监控工具 JavaMelody 的集成过程，使项目更加健壮。在 JAVA Web 项目某些场景中，我们需要用缓存解决如热点数据访问的性能问题，业界常用的中间件如 Memcached 、 Redis 等。相比 Memcached ，Redis 支持更丰富的数据结构。本篇将主要介绍在 Spring Boot 中集成 Redis 的过程。 二、集成 Redis在 Spring Boot 中使用 Redis 有两种方式： 基于 RedisTemplate 类，该类是 Spring Data 提供的工具，可以直接注入使用。 基于 Jedis，Jedis 是 Redis 官方推荐的面向 JAVA 的客户端。 本文将介绍第一种使用方式。 2.1 引入依赖包其实 Spring Boot 提供的父工程中已经包含了所依赖的 Redis jar 包，我们只需在相应模块引入即可。第一篇我们已经提到过 demo-common 层是公用组件层，那么 Redis 相关的声明及配置应该在该层定义。于是乎在 demo-common 层的 pom 文件中引入 Redis 的依赖包。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2.2 RedisTemplate 的自动配置其实我们现在就可以在项目中注入 RedisTemplate 并使用了，至于原因，首先看下「 RedisAutoConfiguration 」类的源码：1234567891011121314151617181920212223242526@Configuration@ConditionalOnClass(&#123;RedisOperations.class&#125;)@EnableConfigurationProperties(&#123;RedisProperties.class&#125;)@Import(&#123;LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class&#125;)public class RedisAutoConfiguration &#123; public RedisAutoConfiguration() &#123; &#125; @Bean @ConditionalOnMissingBean( name = &#123;"redisTemplate"&#125; ) public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; &#125; @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125; 从源码可以看出，Spring Boot 会自动帮我们生成了一个 RedisTemplate 及一个 StringRedisTemplate ，但是这个 RedisTemplate 的泛型是 &lt;Object, Object&gt; ，如果我们直接使用就需要处理各种类型转换。所以为了方便使用，我们需要自定义一个泛型为 &lt;String, Object&gt; 的 RedisTemplate 。而 @ConditionalOnMissingBean 注解的作用是在当前 Spring 上下文中不存在某个对象时，才会自动实例化一个 Bean 。因此我们可以自定义 RedisTemplate 从而替代默认的。 2.2 自定义 Redis 配置类Spring Data 提供了若干个 Serializer ，主要包括： JdkSerializationRedisSerializer — 使用 JAVA 自带的序列化机制将对象序列化为一个字符串 OxmSerializer — 将对象序列化为 XML 字符串 Jackson2JsonRedisSerializer — 将对象序列化为 JSON 字符串 其中 RedisTemplate 默认的序列化方式是 Jdk ，虽然是效率比较高但是序列化结果的字符串是最长的。而 JSON 由于其数据格式的紧凑型，序列化结果的字符串是最小的，即占用的内存最小。所以我们选择用 Jackson 替代默认的 Jdk 方式。 ① 首先在项目父 pom 文件中定义 Jackson 的版本号且声明 Jackson 依赖。1234&lt;properties&gt; ...省略其余部分... &lt;jackson.version&gt;2.9.4&lt;/jackson.version&gt;&lt;/properties&gt; 123456789101112131415&lt;dependencyManagement&gt; &lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; ② 其次在 demo-common 层的 pom 文件中添加上述 Jackson 依赖。1234567891011&lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ③ 最后在 demo-common 层创建 com.example.demo.common 包，添加 Redis 目录并在其中创建 RedisConfig 配置类。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.example.demo.common.redis;import com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.SerializationFeature;import com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * @author linjian * @date 2019/3/2 */@Configurationpublic class RedisConfig &#123; @Bean @SuppressWarnings("all") public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); objectMapper.registerModule(new JavaTimeModule()); objectMapper.findAndRegisterModules(); objectMapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false); // 使用 Jackson2JsonRedisSerialize 替换默认序列化 Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;String, Object&gt;(); redisTemplate.setConnectionFactory(factory); // key 采用 String 的序列化方式 redisTemplate.setKeySerializer(stringRedisSerializer); // hash 的 key 也采用 String 的序列化方式 redisTemplate.setHashKeySerializer(stringRedisSerializer); // value 序列化方式采用 jackson redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); // hash 的 value 序列化方式采用 jackson redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125;&#125; 2.3 自定义 Redis 工具类直接使用 RedisTemplate 操作 Redis 需要很多额外的代码，最好封装成一个工具类，使用时直接注入。① 定义一个常用的缓存时间常量类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.example.demo.common.redis;/** * @author linjian * @date 2019/3/2 */public class CacheTime &#123; /** * 缓存时效 5秒钟 */ public static int CACHE_EXP_FIVE_SECONDS = 5; /** * 缓存时效 1分钟 */ public static int CACHE_EXP_MINUTE = 60; /** * 缓存时效 5分钟 */ public static int CACHE_EXP_FIVE_MINUTES = 60 * 5; /** * 缓存时效 10分钟 */ public static int CACHE_EXP_TEN_MINUTES = 60 * 10; /** * 缓存时效 15分钟 */ public static int CACHE_EXP_QUARTER_MINUTES = 60 * 15; /** * 缓存时效 60分钟 */ public static int CACHE_EXP_HOUR = 60 * 60; /** * 缓存时效 12小时 */ public static int CACHE_EXP_HALF_DAY = 12 * 60 * 60; /** * 缓存时效 1天 */ public static int CACHE_EXP_DAY = 3600 * 24; /** * 缓存时效 1周 */ public static int CACHE_EXP_WEEK = 3600 * 24 * 7; /** * 缓存时效 1月 */ public static int CACHE_EXP_MONTH = 3600 * 24 * 30 * 7; /** * 缓存时效 永久 */ public static int CACHE_EXP_FOREVER = 0;&#125; ② 定义工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627package com.example.demo.common.redis;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Component;import org.springframework.util.CollectionUtils;import java.util.List;import java.util.Map;import java.util.Set;import java.util.concurrent.TimeUnit;/** * @author linjian * @date 2019/3/2 */@Componentpublic class RedisClient &#123; @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; /** * 指定缓存失效时间 * * @param key 键 * @param time 时间(秒) * @return */ public boolean expire(String key, long time) &#123; try &#123; if (time &gt; 0) &#123; redisTemplate.expire(key, time, TimeUnit.SECONDS); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 根据key 获取剩余过期时间 * * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ public long ttl(String key) &#123; return redisTemplate.getExpire(key, TimeUnit.SECONDS); &#125; /** * 判断key是否存在 * * @param key 键 * @return true 存在 false不存在 */ public boolean exists(String key) &#123; try &#123; return redisTemplate.hasKey(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 删除缓存 * * @param key 可以传一个值 或多个 */ @SuppressWarnings("unchecked") public void del(String... key) &#123; if (key != null &amp;&amp; key.length &gt; 0) &#123; if (key.length == 1) &#123; redisTemplate.delete(key[0]); &#125; else &#123; redisTemplate.delete(CollectionUtils.arrayToList(key)); &#125; &#125; &#125; /** * 模糊匹配批量删除 * * @param pattern 匹配的前缀 */ public void deleteByPattern(String pattern) &#123; Set&lt;String&gt; keys = redisTemplate.keys(pattern); if (!CollectionUtils.isEmpty(keys)) &#123; redisTemplate.delete(keys); &#125; &#125; /** * 设置指定 key 的值 * * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 * @return true成功 false 失败 */ public boolean set(String key, Object value, long time) &#123; try &#123; if (time == CacheTime.CACHE_EXP_FOREVER) &#123; redisTemplate.opsForValue().set(key, value); &#125; else &#123; redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 获取指定 key 的值 * * @param key 键 * @return 值 */ @SuppressWarnings("unchecked") public &lt;T&gt; T get(String key) &#123; return key == null ? null : (T) redisTemplate.opsForValue().get(key); &#125; /** * 将 key 中储存的数字值递增 * * @param key 键 * @param delta 要增加几(大于0) * @return */ public long incr(String key, long delta) &#123; if (delta &lt;= 0) &#123; throw new IllegalArgumentException("递增因子必须大于0"); &#125; return redisTemplate.opsForValue().increment(key, delta); &#125; /** * 将 key 中储存的数字值递减 * * @param key 键 * @param delta 要减少几(小于0) * @return */ public long decr(String key, long delta) &#123; if (delta &lt;= 0) &#123; throw new IllegalArgumentException("递减因子必须大于0"); &#125; return redisTemplate.opsForValue().increment(key, -delta); &#125; /** * 将哈希表 key 中的字段 field 的值设为 value * * @param key 键 * @param field 字段 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 * @return true 成功 false失败 */ public boolean hset(String key, String field, Object value, long time) &#123; try &#123; redisTemplate.opsForHash().put(key, field, value); if (time != CacheTime.CACHE_EXP_FOREVER) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 同时将多个 field-value (域-值)对设置到哈希表 key 中 * * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) * @return true成功 false失败 */ public boolean hmset(String key, Map&lt;String, Object&gt; map, long time) &#123; try &#123; redisTemplate.opsForHash().putAll(key, map); if (time != CacheTime.CACHE_EXP_FOREVER) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 删除一个或多个哈希表字段 * * @param key 键 * @param field 字段 可以多个 */ public void hdel(String key, Object... field) &#123; redisTemplate.opsForHash().delete(key, field); &#125; /** * 获取存储在哈希表中指定字段的值 * * @param key 键 * @param field 字段 * @return 值 */ public &lt;T&gt; T hget(String key, String field) &#123; return (T) redisTemplate.opsForHash().get(key, field); &#125; /** * 获取在哈希表中指定 key 的所有字段和值 * * @param key 键 * @return 对应的多个键值 */ public Map&lt;Object, Object&gt; hmget(String key) &#123; return redisTemplate.opsForHash().entries(key); &#125; /** * 查看哈希表 key 中，指定的字段是否存在 * * @param key 键 * @param field 字段 * @return true 存在 false不存在 */ public boolean hexists(String key, String field) &#123; return redisTemplate.opsForHash().hasKey(key, field); &#125; /** * 获取哈希表中字段的数量 * * @param key 键 * @return 字段数量 */ public long hlen(String key) &#123; try &#123; return redisTemplate.opsForHash().size(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0L; &#125; &#125; /** * 向集合添加一个或多个成员 * * @param key 键 * @param time 时间(秒) * @param values 成员 可以是多个 * @return 成功个数 */ public long sadd(String key, long time, Object... values) &#123; try &#123; Long count = redisTemplate.opsForSet().add(key, values); if (time != CacheTime.CACHE_EXP_FOREVER) &#123; expire(key, time); &#125; return count; &#125; catch (Exception e) &#123; e.printStackTrace(); return 0L; &#125; &#125; /** * 移除集合中一个或多个成员 * * @param key 键 * @param values 成员 可以是多个 * @return 移除的个数 */ public long srem(String key, Object... values) &#123; try &#123; return redisTemplate.opsForSet().remove(key, values); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0L; &#125; &#125; /** * 返回集合中的所有成员 * * @param key 键 * @return 成员列表 */ public &lt;T&gt; Set&lt;T&gt; smembers(String key) &#123; try &#123; return (Set&lt;T&gt;) redisTemplate.opsForSet().members(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 判断 member 元素是否是集合 key 的成员 * * @param key 键 * @param member 成员 * @return true 存在 false不存在 */ public boolean sismember(String key, Object member) &#123; try &#123; return redisTemplate.opsForSet().isMember(key, member); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 获取集合的成员数 * * @param key 键 * @return 成员数 */ public long slen(String key) &#123; try &#123; return redisTemplate.opsForSet().size(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0L; &#125; &#125; /** * 在列表头部添加一个值 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return boolean */ public boolean lpush(String key, Object value, long time) &#123; try &#123; redisTemplate.opsForList().leftPush(key, value); if (time != CacheTime.CACHE_EXP_FOREVER) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 在列表头部添加多个值 * * @param key 键 * @param values 值 * @param time 时间(秒) * @return boolean */ public boolean lpush(String key, List&lt;Object&gt; values, long time) &#123; try &#123; redisTemplate.opsForList().leftPushAll(key, values); if (time != CacheTime.CACHE_EXP_FOREVER) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 在列表尾部添加一个值 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return boolean */ public boolean rpush(String key, Object value, long time) &#123; try &#123; redisTemplate.opsForList().rightPush(key, value); if (time != CacheTime.CACHE_EXP_FOREVER) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 在列表尾部添加多个值 * * @param key 键 * @param values 值 * @param time 时间(秒) * @return boolean */ public boolean rpush(String key, List&lt;Object&gt; values, long time) &#123; try &#123; redisTemplate.opsForList().rightPushAll(key, values); if (time != CacheTime.CACHE_EXP_FOREVER) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 移除列表元素 * * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ public long lrem(String key, long count, Object value) &#123; try &#123; return redisTemplate.opsForList().remove(key, count, value); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 通过索引设置列表元素的值 * * @param key 键 * @param index 索引 * @param value 值 * @return boolean */ public boolean lset(String key, long index, Object value) &#123; try &#123; redisTemplate.opsForList().set(key, index, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 获取列表指定范围内的元素 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return 元素列表 */ @SuppressWarnings("unchecked") public &lt;T&gt; List&lt;T&gt; lrange(String key, long start, long end) &#123; try &#123; return (List&lt;T&gt;) redisTemplate.opsForList().range(key, start, end); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 通过索引获取列表中的元素 * * @param key 键 * @param index 索引 index&gt;=0时， 0 表头，1 第二个元素，依次类推；index&lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * @return */ public Object lindex(String key, long index) &#123; try &#123; return redisTemplate.opsForList().index(key, index); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 获取列表长度 * * @param key 键 * @return 列表长度 */ public long llen(String key) &#123; try &#123; return redisTemplate.opsForList().size(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0L; &#125; &#125; /** * 向有序集合添加一个成员，或者更新已存在成员的分数 * * @param key 键 * @param time 时间(秒) * @param member 成员 * @param score 分数 * @return */ public boolean zadd(String key, long time, Object member, double score) &#123; try &#123; boolean ret = redisTemplate.opsForZSet().add(key, member, score); if (time != CacheTime.CACHE_EXP_FOREVER) &#123; expire(key, time); &#125; return ret; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 移除有序集合中的一个或多个成员 * * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ public long zrem(String key, Object... values) &#123; try &#123; return redisTemplate.opsForZSet().remove(key, values); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0L; &#125; &#125; /** * 通过索引区间返回有序集合成指定区间内的成员 分数从低到高 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return 成员集合 */ public Set&lt;Object&gt; zrange(String key, long start, long end) &#123; try &#123; return redisTemplate.opsForZSet().range(key, start, end); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 通过索引区间返回有序集合成指定区间内的成员 分数从高到低 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return 成员集合 */ public Set&lt;Object&gt; zrevrange(String key, long start, long end) &#123; try &#123; return redisTemplate.opsForZSet().range(key, start, end); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 返回有序集合中某个成员的分数值 * * @param key 键 * @param member 成员 * @return 分数值 */ public double zscore(String key, Object member) &#123; try &#123; return redisTemplate.opsForZSet().score(key, member); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0.0; &#125; &#125; /** * 判断有序集合中某个成员是否存在 * * @param key 键 * @param member 成员 * @return true 存在 false不存在 */ public boolean zexist(String key, Object member) &#123; try &#123; return null != redisTemplate.opsForZSet().score(key, member); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 获取有序集合的成员数 * * @param key 键 * @return 成员数 */ public long zlen(String key) &#123; try &#123; return redisTemplate.opsForZSet().size(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0L; &#125; &#125;&#125; 2.4 添加 Redis 常用配置项在 application.properties 文件中的添加 Redis 相关的配置项：123456789101112131415161718# 数据库索引（默认为0）spring.redis.database = 1# 服务器地址spring.redis.host = 127.0.0.1# 服务器连接端口spring.redis.port = 6379# 服务器连接密码（默认为空）spring.redis.password =# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait = -1# 连接超时时间（毫秒）spring.redis.timeout = 3000 # 连接池最大连接数spring.redis.jedis.pool.max-active = 8# 连接池中的最大空闲连接spring.redis.jedis.pool.max-idle = 8# 连接池中的最小空闲连接spring.redis.jedis.pool.min-idle = 1 2.5 Redis 缓存测试① 首先在 DemoService 中注入 RedisClient ，修改 test 方法将 user 对象以 user:1 为键存放到 Redis 中。 Redis 开发规范：https://yq.aliyun.com/articles/531067 123456789101112131415161718192021222324252627282930package com.example.demo.biz.service.impl;import com.example.demo.biz.service.DemoService;import com.example.demo.common.redis.CacheTime;import com.example.demo.common.redis.RedisClient;import com.example.demo.dao.entity.UserDO;import com.example.demo.dao.mapper.business.UserMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * @author linjian * @date 2019/1/15 */@Servicepublic class DemoServiceImpl implements DemoService &#123; @Autowired private UserMapper userMapper; @Autowired private RedisClient redisClient; @Override public String test() &#123; UserDO user = userMapper.selectById(1); redisClient.set("user:1", user, CacheTime.CACHE_EXP_FIVE_MINUTES); return user.toString(); &#125;&#125; ② 之后使用 Redis Desktop Manager 客户端连接 Redis 服务器，选择数据库「 1 」，查看刚存放的缓存。 三、结语至此 Spring Boot 集成 Redis 的具体步骤介绍完毕，我们自定义了 Redis 的序列化方式，并通过一个简单的例子测试了 Redis 的可用性，相关代码已同步至 GitHub 。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 项目实战（三）集成 Swagger 及 JavaMelody]]></title>
    <url>%2F2019%2F02%2F02%2Fspringboot-3%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了 Logback 的集成过程，总体已经达到了基本可用的项目结构。本篇主要介绍两个常用工具，接口文档工具 Swagger 、项目监控工具 JavaMelody 的集成步骤。 二、Swagger随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染变成了前端渲染、前后端分离的形态。前后端唯一的联系变成了 API 接口，API 文档成了前后端开发人员联系的纽带，Swagger 就是一款让我们更好书写 API 文档的框架。 2.1 为什么要用 Swagger在日常开发过程中，有一个问题始终困扰着我们，那就是接口文档的可靠性。想必我们都经历过接口变动但接口文档没更新的窘境。单独维护接口文档不仅费时费力，而且会经常遗漏。Swagger 通过在接口及实体上添加几个注解的方式就能在项目启动后自动生成接口文档，尽管这样会带来一定的代码侵入性，但与其带来的好处相比就微不足道了。 2.2 集成 Swagger① 首先在项目父 pom 文件中定义 Swagger 的版本号且声明 Swagger 依赖。1234&lt;properties&gt; ...省略其余部分... &lt;swagger.version&gt;2.8.0&lt;/swagger.version&gt;&lt;/properties&gt; 123456789101112131415&lt;dependencyManagement&gt; &lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;swagger.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; ② 其次在 demo-web 层中的 pom 文件中添加上述依赖1234567891011&lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ③ 然后在 com.example.demo.web 包中添加 config 目录并新建 Swagger 配置文件，具体内容如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.example.demo.web.config;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;/** * @author linjian * @date 2019/2/2 */@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Value(value = "$&#123;swagger.enabled&#125;") private Boolean swaggerEnabled; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .enable(swaggerEnabled) .select() .apis(RequestHandlerSelectors.basePackage("com.example.demo.web.controller")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("接口文档") .description("Spring Boot 集成 Swagger") .termsOfServiceUrl("https://symonlin.github.io") .version("1.0") .build(); &#125;&#125; 其中 「 swaggerEnabled 」表示是否开启 Swagger，一般线上环境是关闭的，所以可在 application.properties 文件中设置配置项。「 apis 」设置了 controller 的包路径。 ④ 随后在先前创建的 DemoController 中添加 Swagger 的相关注解。12345678910111213141516171819202122232425262728package com.example.demo.web.controller;import com.example.demo.biz.service.DemoService;import io.swagger.annotations.Api;import io.swagger.annotations.ApiOperation;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author linjian * @date 2019/1/15 */@Api(tags = "demo")@RestController@RequestMapping("demo")public class DemoController &#123; @Autowired private DemoService demoService; @GetMapping("test") @ApiOperation("测试") public String test() &#123; return demoService.test(); &#125;&#125; ⑤ 最后启动项目，访问 http://localhost:8080/swagger-ui.html 测试 Swagger。 ⑥ 使用 Swagger UI 测试 test 接口，点击「 Try it out 」&gt;&gt; 「 Execute 」 2.3 Swagger 常用注解说明 注解 说明 使用位置 @Api 描述 controller 的作用 用于 controller 类上 @ApiOperation 描述 controller 方法的作用 用于 controller 方法上 @ApiParam 描述 controller 方法参数的作用 用于 controller 方法的参数上 @ApiModel 描述对象的作用 用于请求对象或者返回结果对象上 @ApiModelProperty 描述对象里字段的作用 用于请求对象或者返回结果对象里的字段上 注：其余注解大家可自行查阅文档 三、JavaMelody3.1 JavaMelody 介绍JavaMelody 是用来在 QA 和实际运行生产环境中监控 Java 或 Java EE 应用程序服务器的一个开源框架。它不是一个工具来模拟来自用户的请求，而是一个测量和计算用户在实际操作中应用程序的使用情况的工具，并以图表的形式显示，图表可以按天，周，月，年或自定义时间段查看。 3.2 集成 JavaMelody① 首先在项目父 pom 文件中声明 JavaMelody 依赖12345&lt;dependency&gt; &lt;groupId&gt;net.bull.javamelody&lt;/groupId&gt; &lt;artifactId&gt;javamelody-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.74.0&lt;/version&gt;&lt;/dependency&gt; ② 其次在 demo-web 层中的 pom 文件中添加上述依赖1234567&lt;dependencies&gt; ...省略其余部分... &lt;dependency&gt; &lt;groupId&gt;net.bull.javamelody&lt;/groupId&gt; &lt;artifactId&gt;javamelody-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ③ 最后启动项目，访问 http://localhost:8080/monitoring 查看④ 为了加强安全性，修改默认访问地址以及设置为登录后才可访问，可在 application.properties 文件中添加以下配置项12javamelody.init-parameters.authorized-users = admin:pwdjavamelody.init-parameters.monitoring-path = /demo/monitoring 四、结语至此，Swagger 及 JavaMelody 的集成步骤已介绍完毕。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Logback XML 基础配置详解]]></title>
    <url>%2F2019%2F01%2F29%2Flogback-1%2F</url>
    <content type="text"><![CDATA[XML 配置文件的基本结构：以 &lt;configuration> 开头，后面有零个或多个 &lt;appender> 元素，有零个或多个 &lt;logger> 元素，有最多一个 &lt;root> 元素。 1. &lt;configuration>根节点 &lt;configuration> 包含以下三个属性： scan ：当此属性设置为 true 时，配置文件如果发生改变将被重新加载，默认值为 true。 scanPeriod ：设置监测配置文件是否有修改的时间间隔，默认为一分钟，如果没有给出时间单位则默认为毫秒。当 scan 为 true 时，此属性生效。 debug ：当此属性设置为 true 时，将打印出 Logback 内部日志信息，实时查看 Logback 运行状态，默认值为 false。 123&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; ...省略其余部分...&lt;/configuration&gt; 2. &lt;contextName>子节点 &lt;contextName> 用来设置上下文名称，每个 logger 都关联到上下文，默认上下文名称为 default。可以使用该元素设置成其他名称，用于区分不同应用程序。1234&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;contextName&gt;demo&lt;/contextName&gt; ...省略其余部分...&lt;/configuration&gt; 3. &lt;property>子节点 &lt;property> 用来定义变量，有两个属性 name 和 value，可以通过 「 ${} 」在 logger 上下文中使用变量。123456&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;contextName&gt;demo&lt;/contextName&gt; &lt;property name="log.root" value="./logs"/&gt; &lt;property name="log.pattern" value="[%d&#123;'MM-dd HH:mm:ss,SSS',GMT+8:00&#125;] %level [%thread] %logger&#123;0&#125;[%line] - %msg%n"/&gt; ...省略其余部分...&lt;/configuration&gt; 4. &lt;appender>子节点 &lt;appender> 是负责写日志的组件，有两个必要属性 name 和 class。 name ：指定 appender 名称 class ：指定 appender 的全限定类名 下面介绍几种常用的类型： 4.1 ConsoleAppenderConsoleAppender 的作用是将日志输出到控制台12345&lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;log.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; &lt;encoder> 表示对日志进行格式化，是 0.9.19 版本之后引进的，以前的版本使用 &lt;layout>，前者是目前官方推荐的。它负责两件事，一是把日志信息转换成字节数组，二是把字节数组写入到输入流。目前 PatternLayoutEncoder 是唯一有用的且默认的 encoder，有一个 &lt;pattern> 节点用来设置日志的格式，使用「 % + 转换符 」的方式。 常用转换符 描述 date{pattern} / d{pattern} 输出时间格式，模式语法与 java.text.SimpleDateFormat 兼容 level / le / p 输出日志级别 thread / t 输出生成日志的线程名称 logger{length} / lo{length} / c{length} 输出日志的 logger 名称，length 可缩短名称，不输入表示输出完整全限定类名，输入 0 表示只输出类名，输入其他数字表示在保证输出包路径首字母及类名的前提下根据剩余 length 的值是否大于从右向左的完整目录名长度决定输出首字母还是完整目录名 line / L 输出执行日志的行号 message / msg / m 输出日志消息 n 换行符 -N 从左到右显示 N 个字符宽度 4.2 FileAppenderFileAppender 的作用是将日志输出到文件中1234567&lt;appender name="FILE" class="ch.qos.logback.core.FileAppender"&gt; &lt;file&gt;$&#123;log.root&#125;/demo.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;log.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; 子节点 描述 &lt;file> 表示写入的文件名，可以是相对路径也可以是绝对路径，如果上级目录不存在则自动创建 &lt;append> 如果为 true 表示日志被追加到文件结尾，如果为 false 表示清空现有文件，默认是 true &lt;encoder> 同上 &lt;prudent> 如果为 true 表示日志会被安全地写入文件，即使其他的 FileAppender 也在向此文件做写入操作，效率低，默认为 false 4.3 RollingFileAppenderRollingFileAppender 的作用是滚动记录文件，先将日志记录到指定文件，当符合某个条件时再将日志记录到其他文件123456789&lt;appender name="DEMO" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;log.root&#125;/demo.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;log.root&#125;/demo.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;log.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; 常用子节点 描述 &lt;file> 同上 &lt;append> 同上 &lt;rollingPolicy> 当发生滚动时决定 RollingFileAppender 的行为，涉及到文件移动和重命名 &lt;encoder> 同上 上述 &lt;rollingPolicy> 属性 class 定义具体的滚动策略类，「 TimeBasedRollingPolicy 」是最常用的滚动策略，它根据时间制定滚动策略，既负责滚动也负责触发滚动。有以下子节点： 常用子节点 描述 &lt;fileNamePattern> 必要节点，包含文件名及「 %d 」转换符，「 %d 」可以包含一个 java.text.SimpleDateFormat 类指定的时间格式，如 %d{yyyy-MM}，如果直接使用则默认格式为 yyyy-MM-dd &lt;maxHistory> 可选节点，控制保留的归档文件的最大数量，超出数量则删除旧文件 RollingFileAppender 的 &lt;file> 子节点可有可无，如果没设置则会根据 &lt;fileNamePattern> 的值每隔一段时间改变一次。 5. &lt;logger>子节点 &lt;logger> 是用来设置某一个包或具体某一个类的日志级别以及指定要使用的 appender。它有三个属性，一个必选的 name 属性，一个可选的 level 属性和一个可选的 addtivity 属性。可以包含零个或多个 &lt;appender-ref> 元素，标识该 appender 将会添加到这个 logger。 name ：用来指定受此 logger 约束的某一个包或者具体的一个类 level ：用来设置日志级别，大小写无关。五个常用的日志级别从低至高依次为 TRACE 、 DEBUG 、 INFO 、 WARN 、 ERROR ，如果未设置此属性，那么当前 logger 将会继承上级的日志级别 addtivity ：是否向上级 logger 传递打印信息，默认为 true 6. &lt;root>子节点 &lt;root> 也是 &lt;logger> 元素，但它是根 logger，是所有 logger 的上级。只有一个 level 属性，因为 name 已经被命名为「 root 」了。默认日志级别为 DEBUG。 7. &lt;filter>&lt;filter> 是 &lt;appender> 的一个子节点，表示在当前设置的日志级别下再进行一次过滤，最基本的 filter 为 LevelFilter 和 ThresholdFilter。 7.1 LevelFilterLevelFilter 即级别过滤器，根据日志级别进行过滤。如果日志级别等于配置级别，过滤器会根据 onMath 和 onMismatch 的值接收或拒绝日志。有以下子节点： &lt;level> ：设置日志级别 &lt;onMatch> ：用于配置符合过滤条件的操作 &lt;onMismatch> ：用于配置不符合过滤条件的操作 例：将过滤器的日志级别配置为 INFO，所有 INFO 级别的日志交给 appender 处理，非 INFO 级别的日志被过滤掉。 ① 首先定义一个 ConsoleAppender 类型的 appender，再在其中声明一个 class 为 LevelFilter 的 filter。123456789101112131415161718&lt;configuration scan="true" scanPeriod="60 seconds" debug="false" &gt; &lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;'MM-dd HH:mm:ss,SSS',GMT+8:00&#125;] %level [%thread] %logger&#123;0&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;root level="DEBUG"&gt; &lt;appender-ref ref="CONSOLE"/&gt; &lt;/root&gt; &lt;/configuration&gt; ② 新建日志输出单元测试类1234567891011public class LogbackTest &#123; @Test public void testLog() &#123; log.trace("=====trace====="); log.debug("=====debug====="); log.info("=====info====="); log.warn("=====warn====="); log.error("=====error====="); &#125;&#125; ③ 输出结果为：1[01-29 10:44:00,254] INFO [main] LogbackTest - =====info===== 可以看到，尽管 &lt;root> 配置的日志级别为 DEBUG，但是输出的只有 INFO 。 7.2 ThresholdFilterThresholdFilter 即临界值过滤器，过滤掉低于指定临界值的日志。当日志级别等于或高于临界值时，过滤器返回NEUTRAL；当日志级别低于临界值时，日志会被拒绝。 例：过滤掉所有低于INFO级别的日志。 ① 首先定义一个 ConsoleAppender 类型的 appender，再在其中声明一个 class 为 ThresholdFilter 的 filter。12345678910111213141516&lt;configuration scan="true" scanPeriod="60 seconds" debug="false" &gt; &lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;'MM-dd HH:mm:ss,SSS',GMT+8:00&#125;] %level [%thread] %logger&#123;0&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;root level="DEBUG"&gt; &lt;appender-ref ref="CONSOLE"/&gt; &lt;/root&gt;&lt;/configuration&gt; ② 运行 Logback 单元测试类的 testLog 方法，输出结果为：123[01-29 10:46:39,937] INFO [main] LogbackTest - =====info=====[01-29 10:46:39,937] WARN [main] LogbackTest - =====warn=====[01-29 10:46:39,937] ERROR [main] LogbackTest - =====error===== 可以看到，尽管 &lt;root> 配置的日志级别为 DEBUG，但是输出的只有 INFO 及以上级别的。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Logback</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 项目实战（二）集成 Logback]]></title>
    <url>%2F2019%2F01%2F27%2Fspringboot-2%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了 Spring Boot Maven 多模块项目的搭建方法以及 MyBatis 的集成。通常在调试接口或者排查问题时我们主要借助于日志，一个设计合理的日志文件配置能大大降低我们的排查难度，本篇主要介绍 Logback 集成步骤。 二、集成 Logback2.1 引入依赖包其实 Spring Boot 提供的父工程中已经包含了所依赖的 Logback jar 包，可通过项目父 pom 中的 「spring-boot-starter-parent」&gt;&gt; 「spring-boot-dependencies」找到 Logback 的三个依赖包。123456789101112131415&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt;&lt;/dependency&gt; 2.2 简单日志配置在自定义日志配置之前我们可以先尝试一下 Spring Boot 默认的日志配置，可通过修改 application.properties 文件中的配置项设置。 ① 更改默认日志级别默认情况下 Spring Boot 从控制台打印出来的日志级别只有 ERROR、WARN、INFO 这三种，如果需要打印 DEBUG 级别的日志，可以使用以下配置项设置。1logging.level.root = DEBUG ② 将日志输出到文件中默认情况下 Spring Boot 只会在控制台打印日志，可以使用「 logging.path 」或「 logging.file 」其中一个配置项将日志输出到文件中。123logging.path = ./logs或logging.file = ./logs/demo.log 注意事项： logging.path 和 logging.file 都可以是相对路径或者绝对路径 但它们两个是不会叠加的，也就是说即使同时配置 logging.path = ./logs 与 logging.file = demo.log 也不会在 ./logs 目录下 生成 demo.log 文件，实际结果是最终只在项目根目录生成了 demo.log 文件。 当只配置 logging.path 时，会在该 path 下生成一个 spring.log 文件，该文件名是固定的无法修改，若 path 不存在则会自动创建该路径。 2.3 自定义日志配置我们可能需要将一些特定包或者特定级别的日志打印到单独的文件中方便排查问题，显然默认的日志配置并不能满足我们需求，需要我们自定义。 2.3.1 Logback XML 基础配置介绍首先熟悉下常规的配置项，详见：Logback XML 基础配置详解 2.3.2 自定义日志配置文件内容解析然后在 demo-web 层的 resources 目录下创建名为「 logback.xml 」的文件，具体内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- 每隔一分钟扫描配置文件 --&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;!-- 设置上下文名称为 demo --&gt; &lt;contextName&gt;demo&lt;/contextName&gt; &lt;!-- 定义日志输出格式变量：%d表示时间 花括号内为时间格式 %level表示日志级别 %thread表示线程名 %logger&#123;0&#125;表示输出日志的类名 [%line]表示行号用方括号包裹 %msg表示日志消息 %n换行 --&gt; &lt;property name="log.pattern" value="[%d&#123;'MM-dd HH:mm:ss,SSS'&#125;] %level [%thread] %logger&#123;0&#125;[%line] - %msg%n"/&gt; &lt;!-- 定义日志字符集 --&gt; &lt;property name="log.charset" value="UTF-8"/&gt; &lt;!-- 定义日志级别 --&gt; &lt;property name="log.level" value="INFO"/&gt; &lt;!-- 定义日志存放路径 --&gt; &lt;property name="log.path" value="logs"/&gt; &lt;!-- 输出到控制台 --&gt; &lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- 日志输出格式 --&gt; &lt;encoder&gt; &lt;!-- 日志字符集 --&gt; &lt;charset&gt;$&#123;log.charset&#125;&lt;/charset&gt; &lt;!-- 日志输出格式 --&gt; &lt;pattern&gt;$&#123;log.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出日志 --&gt; &lt;appender name="COMMON" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!-- 写入的文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/common.log&lt;/file&gt; &lt;!-- 追加到文件结尾 --&gt; &lt;append&gt;true&lt;/append&gt; &lt;!-- 滚动策略：按照每天生成日志文件 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- 每天日志归档路径及文件名格式 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/common.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;!-- 日志文件保留天数 --&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;charset&gt;$&#123;log.charset&#125;&lt;/charset&gt; &lt;pattern&gt;$&#123;log.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;log.path&#125;/error.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/error.%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;!-- 单日志文件最大限制100兆 超过则将文件内容归档到按照 fileNamePattern 命名的文件中 源文件则清空 --&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 级别过滤器匹配 ERROR 级别日志 --&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;charset&gt;$&#123;log.charset&#125;&lt;/charset&gt; &lt;pattern&gt;$&#123;log.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="DB" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;log.path&#125;/db.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/db.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;charset&gt;$&#123;log.charset&#125;&lt;/charset&gt; &lt;pattern&gt;$&#123;log.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 指定 com.example.demo.dao.mapper 包要使用的 appender 且不向上级传递 --&gt; &lt;logger name="com.example.demo.dao.mapper" level="DEBUG" additivity="false"&gt; &lt;!-- 指定使用 DB 及 ERROR 这两个 appender --&gt; &lt;appender-ref ref="DB"/&gt; &lt;appender-ref ref="ERROR"/&gt; &lt;/logger&gt; &lt;!-- 根 logger --&gt; &lt;root level="$&#123;log.level&#125;"&gt; &lt;appender-ref ref="CONSOLE"/&gt; &lt;appender-ref ref="COMMON"/&gt; &lt;appender-ref ref="ERROR"/&gt; &lt;/root&gt;&lt;/configuration&gt; 2.3.3 多环境自定义日志配置然而，上述配置中 &lt;property> 标签的值都是写死的，但我们的项目环境可能有多套，每套环境的日志配置都有所区别，这就需要借助 Spring Boot 提供的 &lt;springProfile> 及 &lt;springProperty> 标签解决。 ① 首先将刚才新建的 「 logback.xml 」文件重命名为「 logback-spring.xml 」。 注：因为文件的命名与加载顺序有关，logback.xml 早于 application.properties 加载，而 logback-spring.xml 晚于 application.properties 加载。而且 logback-spring.xml 中 Spring Boot 提供了一些特定的配置项支持，如 &lt;springProperty>、&lt;springProfile>。 ② 其次将 &lt;property> 标签定义的配置项改为使用 &lt;springProperty> 标签声明。1234&lt;springProperty scope="context" name="log.charset" source="log.charset" defaultValue="UTF-8"/&gt;&lt;springProperty scope="context" name="log.level" source="log.level" defaultValue="INFO"/&gt;&lt;springProperty scope="context" name="log.path" source="log.path" defaultValue="./logs"/&gt;&lt;springProperty scope="context" name="log.pattern" source="log.pattern" defaultValue="[%d&#123;'MM-dd HH:mm:ss,SSS',GMT+8:00&#125;] %level [%thread] %logger&#123;0&#125;[%line] - %msg%n"/&gt; 注：因为只有使用 &lt;springProperty> 标签才能使用 application.properties 文件中的配置项，它的工作方式与 Logback 标准的 &lt;property> 类似，source 指定 application.properties 文件中的配置项。defaultValue 为默认值。 ③ 使用 &lt;springProfile> 标签指定配置生效环境123456789&lt;!-- 开发及测试环境才打印 SQL 日志 --&gt;&lt;springProfile name="dev,test"&gt; &lt;!-- 指定 com.example.demo.dao.mapper 包要使用的 appender 且不向上级传递 --&gt; &lt;logger name="com.example.demo.dao.mapper" level="DEBUG" additivity="false"&gt; &lt;!-- 指定使用 DB 及 ERROR 这两个 appender --&gt; &lt;appender-ref ref="DB"/&gt; &lt;appender-ref ref="ERROR"/&gt; &lt;/logger&gt;&lt;/springProfile&gt; 注：上述配置生效的前提是在 application.properties 文件中指定生效环境（即 spring.profiles.active = dev ） ④ 启动项目可以看到在项目根目录生成 logs 目录，目录中有三个日志文件（即 common.log 、db.log 、error.log ），访问 上篇的 http://localhost:8080/demo/test 接口后 db.log 输出如下日志：123[01-30 17:58:05,296] DEBUG [http-nio-8080-exec-1] selectById[159] - ==&gt; Preparing: SELECT `id`, `user_name` FROM `db_user` WHERE `id` = ? [01-30 17:58:05,317] DEBUG [http-nio-8080-exec-1] selectById[159] - ==&gt; Parameters: 1(Integer)[01-30 17:58:05,373] DEBUG [http-nio-8080-exec-1] selectById[159] - &lt;== Total: 1 三、结语至此 Spring Boot 集成 Logback 的具体步骤介绍完毕，我们自定义了一个简单的日志配置，也看到了最后的输出结果。后续将继续介绍其余中间件或者工具的集成步骤。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Postman 使用技巧之多环境测试及接口依赖关系处理]]></title>
    <url>%2F2019%2F01%2F23%2Ftool-1%2F</url>
    <content type="text"><![CDATA[一、前言在日常开发中，除了正常的单元测试，某些情况我们还需要测试 HTTP 接口，团队中目前使用的是「 Postman 」这款 API调试 、 HTTP 请求工具。通常我们将经常要测试的接口按照项目归类，存放在 Postman 的收藏夹（即 Collections）中方便重复调用。然而，在多个环境测试或者接口之间有依赖关系时我们需要频繁的改动请求体，下面将介绍这两种情况的解决方法。 注：Postman 版本 6.7.1 二、多环境测试2.1 场景项目环境通常都不止一套，每次调试 HTTP 接口时都要修改请求地址是一件非常麻烦的事，所幸 Postman 提供了「 Environment 」管理功能，想要在多个环境中测试只需要切换环境即可。 2.2 解决方法2.2.1 添加环境① 打开 Postman，点击界面右上角的齿轮按钮「 Manage Environment」 ② 点击弹出框中的「 Add 」按钮 ③ 输入 Environment Name，命名规则可为调试环境名+项目名，如「 local alpha」，其中 local 代表本地环境，alpha 代表项目名。然后添加一个名为 host 的变量（即VARIABLE），值为本地环境项目地址，最后点击「 Add 」按钮保存。 2.2.2 切换环境① 回到主界面可以看到 Environment 下拉框已有刚添加的环境选项。 ② 切换环境选择新创建的「 local alpha 」，然后创建一个请求测试项目中已有的 HTTP 接口，请求地址中 host 部分使用刚定义的变量，双层大括号引用变量名，如 {{host}} 。 ③ 请求接口后正常，如需切换一个新环境则按上述步骤操作即可。 三、处理接口之间的依赖关系3.1 场景上面提到了变量的使用方法，在日常开发中有可能遇到这样一个情况：大部分接口都需要用户登录之后才能访问，否则无法请求成功，用户登录成功后通常会有一个 token，此后每次请求都将在 header 中携带该参数用于识别用户身份，此时如果用户重新登录导致 token 发生了变化，那么哪些依赖 token 的接口都要相应的修改，这将是个不小的工作量。 3.2 解决方法3.2.1 添加 Tests 脚本① 首先在用户登录接口的「 Tests 」中添加以下代码。1234567pm.test("Status code is 200", function () &#123; pm.response.to.have.status(200);&#125;);// 把responseBody转为json字符串var data = JSON.parse(responseBody);// 设置环境变量token，供后面的接口引用pm.environment.set("token", data.data); 注：常用的脚本右侧都有相应的快捷方式创建 ② 接口调用成功后会执行上述代码将返回结果中的 data 字段设置到环境变量「 token 」中。 3.2.2 设置变量而后其余依赖 token 的接口可以在 header 中添加 key 为 token，value 为 {{token}} 的参数就可以正常调用接口了。就算重新登录后也不需要手动修改 header 里的 token 值，因为它会从环境变量中读取。 四、结语至此上述两种情况的解决方法已经介绍完了，后续如有调整会再补充。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 项目实战（一）Maven 多模块项目搭建]]></title>
    <url>%2F2019%2F01%2F15%2Fspringboot-1%2F</url>
    <content type="text"><![CDATA[一、前言最近公司项目准备开始重构，框架选定为 Spring Boot ，本篇主要记录了在 IDEA 中搭建 Spring Boot Maven 多模块项目的过程。 二、软件及硬件环境 macOS Sierra 10.12.6 IntelliJ IDEA 2018.2 JDK 1.8 Maven 3.2.1 Spring Boot 2.0.4 三、项目结构 biz 层（业务逻辑层） dao 层（数据持久层） common 层（公用组件层） web 层（请求处理层） 注：biz 层依赖 dao 及 common 层， web 层依赖 biz 层 四、项目搭建4.1 创建父工程① IDEA 主面板选择菜单「Create New Project 」或者工具栏选择菜单「 File -&gt; New -&gt; Project… 」② 侧边栏选择「 Spring Initializr 」，Initializr 默认选择 Default ，然后点击「 Next 」③ 修改 Group 、 Artifact 、 Package 输入框中的值后点击「 Next 」④ 这步暂时先不需要选择，直接点「 Next 」⑤ 点击「 Finish 」创建项目⑥ 最终得到的项目目录结构如下123456789101112131415161718192021222324|-- demo |-- .gitignore |-- mvnw |-- mvnw.cmd |-- pom.xml |-- .mvn | |-- wrapper | |-- maven-wrapper.jar | |-- maven-wrapper.properties |-- src |-- main | |-- java | | |-- com | | |-- example | | |-- demo | | |-- DemoApplication.java | |-- resources | |-- application.properties |-- test |-- java |-- com |-- example |-- demo |-- DemoApplicationTests.java ⑦ 删除无用的 .mvn 目录、 src 目录、 mvnw 及 mvnw.cmd 文件，最终只留 .gitignore 和 pom.xml 4.2 创建子模块① 选择项目根目录，右键呼出菜单，选择「 New -&gt; Module 」② 侧边栏选择「 Maven 」，点击「 Next 」③ 填写 ArifactId ，点击「 Next 」④ 修改 Module name 增加横杠提升可读性，点击「 Finish 」⑤ 同理添加「 demo-dao 」、「 demo-common 」、「 demo-web 」子模块，最终得到项目目录结构如下1234567891011121314151617181920212223242526272829303132333435|-- demo |-- .gitignore |-- pom.xml |-- demo-biz | |-- pom.xml | |-- src | |-- main | | |-- java | | |-- resources | |-- test | |-- java |-- demo-common | |-- pom.xml | |-- src | |-- main | | |-- java | | |-- resources | |-- test | |-- java |-- demo-dao | |-- pom.xml | |-- src | |-- main | | |-- java | | |-- resources | |-- test | |-- java |-- demo-web |-- pom.xml |-- src |-- main | |-- java | |-- resources |-- test |-- java 4.3 整理父 pom 文件中的内容① 删除 dependencies 标签及其中的 spring-boot-starter 和 spring-boot-starter-test 依赖，因为 Spring Boot 提供的父工程已包含，并且父 pom 原则上都是通过 dependencyManagement 标签管理依赖包。 注：dependencyManagement 及 dependencies 的区别自行查阅文档 ② 删除 build 标签及其中的所有内容，spring-boot-maven-plugin 插件作用是打一个可运行的包，多模块项目仅仅需要在入口类所在的模块添加打包插件，这里父模块不需要打包运行。而且该插件已被包含在 Spring Boot 提供的父工程中，这里删掉即可。③ 最后整理父 pom 文件中的其余内容，按其代表含义归类，整理结果如下：1234567891011121314151617181920212223242526272829303132&lt;!-- 基本信息 --&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;demo&lt;/name&gt;&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&lt;!-- 项目说明：这里作为聚合工程的父工程 --&gt;&lt;groupId&gt;com.example.demo&lt;/groupId&gt;&lt;artifactId&gt;demo&lt;/artifactId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;!-- 继承说明：这里继承Spring Boot提供的父工程 --&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;!-- 模块说明：这里声明多个子模块 --&gt;&lt;modules&gt; &lt;module&gt;demo-biz&lt;/module&gt; &lt;module&gt;demo-common&lt;/module&gt; &lt;module&gt;demo-dao&lt;/module&gt; &lt;module&gt;demo-web&lt;/module&gt;&lt;/modules&gt;&lt;!-- 属性说明 --&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;demo.version&gt;0.0.1-SNAPSHOT&lt;/demo.version&gt;&lt;/properties&gt; 4.4 简易 HTTP 接口测试准备工作都完成之后，通过一个简易的 HTTP 接口测试项目是否正常运行。 ① 首先在 demo-web 层创建 com.example.demo.web 包并添加入口类 DemoWebApplication.java 注：com.example.demo.web 为多级目录结构并非单个目录名 123456789101112131415package com.example.demo.web;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @author linjian * @date 2019/1/15 */@SpringBootApplicationpublic class DemoWebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoWebApplication.class, args); &#125;&#125; ② 其次在 demo-web 层的 pom 文件中添加必要的依赖包123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ② 然后在 com.example.demo.web 包中添加 controller 目录并新建一个 controller，添加 test 方法测试接口是否可以正常访问。12345678910111213141516171819package com.example.demo.web.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author linjian * @date 2019/1/15 */@RestController@RequestMapping("demo")public class DemoController &#123; @GetMapping("test") public String test() &#123; return "Hello World!"; &#125;&#125; ③ 最后运行 DemoWebApplication 类中的 main 方法启动项目，默认端口为 8080，访问 http://localhost:8080/demo/test 即可测试接口 4.5 配置模块间的依赖关系通常 JAVA Web 项目会按照功能划分不同模块，模块之间通过依赖关系进行协作，下面将完善模块之间的依赖关系。 ① 首先在父 pom 文件中使用「 dependencyManagement 」标签声明所有子模块依赖12345678910111213141516171819202122232425&lt;!-- 依赖管理：这里统一管理依赖的版本号 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-biz&lt;/artifactId&gt; &lt;version&gt;$&#123;demo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-common&lt;/artifactId&gt; &lt;version&gt;$&#123;demo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-dao&lt;/artifactId&gt; &lt;version&gt;$&#123;demo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-web&lt;/artifactId&gt; &lt;version&gt;$&#123;demo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 注：${demo.version} 定义在 properties 标签中 ② 其次在 demo-biz 层中的 pom 文件中添加 demo-dao 及 demo-common 依赖12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-common&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-dao&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ③ 之后在 demo-web 层中的 pom 文件中添加 demo-biz 依赖123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-biz&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 4.6 web 层调用 biz 层接口测试模块依赖关系配置完成之后，通过 web 层 测试下 biz 层的接口是否可以正常调用。 ① 首先在 demo-biz 层创建 com.example.demo.biz 包，添加 service 目录并在其中创建 DemoService 接口类及 impl 目录（用于存放接口实现类）。12345678910package com.example.demo.biz.service;/** * @author linjian * @date 2019/1/15 */public interface DemoService &#123; String test();&#125; 1234567891011121314151617package com.example.demo.biz.service.impl;import com.example.demo.biz.service.DemoService;import org.springframework.stereotype.Service;/** * @author linjian * @date 2019/1/15 */@Servicepublic class DemoServiceImpl implements DemoService &#123; @Override public String test() &#123; return "interface test"; &#125;&#125; ② DemoController 通过 @Autowired 注解注入 DemoService ，修改 DemoController 的 test 方法使之调用 DemoService 的 test 方法1234567@Autowiredprivate DemoService demoService;@GetMapping("test")public String test() &#123; return demoService.test();&#125; ③ 再次运行 DemoWebApplication 类中的 main 方法启动项目，发现如下报错12345678910111213***************************APPLICATION FAILED TO START***************************Description:Field demoService in com.example.demo.web.controller.DemoController required a bean of type 'com.example.demo.biz.service.DemoService' that could not be found.The injection point has the following annotations: - @org.springframework.beans.factory.annotation.Autowired(required=true)Action:Consider defining a bean of type 'com.example.demo.biz.service.DemoService' in your configuration. 原因是找不到 DemoService 类 ④ 在 DemoWebApplication 入口类中增加包扫描，设置 @SpringBootApplication 注解中的 scanBasePackages 值为 com.example.demo1@SpringBootApplication(scanBasePackages = "com.example.demo") ⑤ 设置完后重新运行 main 方法，项目正常启动，访问 http://localhost:8080/demo/test 测试接口 4.7 集成 MyBatis以上接口均是静态的，不涉及数据库操作，下面将集成 MyBatis 访问数据库中的数据。 ① 首先父 pom 文件中声明 mybatis-spring-boot-starter 及 lombok 依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt;&lt;/dependency&gt; ② 其次在 demo-dao 层中的 pom 文件中添加上述依赖1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; ③ 之后在 demo-dao 层创建 com.example.demo.dao 包，通过 mybatis-genertaor 工具生成 dao 层相关文件（ DO 、 Mapper 、 xml ），目录结构如下123456789101112131415161718|-- demo-dao |-- pom.xml |-- src |-- main | |-- java | | |-- com | | |-- example | | |-- demo | | |-- dao | | |-- entity | | | |-- UserDO.java | | |-- mapper | | |-- UserMapper.java | |-- resources | |-- mybatis | |-- UserMapper.xml |-- test |-- java ④ 然后在 demo-web 层中的 resources 目录 创建 applicatio.properties 文件并在其中添加 datasource 及 MyBatis 相关配置项1234567spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8spring.datasource.username = testspring.datasource.password = 123456mybatis.mapper-locations = classpath:mybatis/*.xmlmybatis.type-aliases-package = com.example.demo.dao.entity 注：如果生成的 xml 在 dao 层 resources 目录的子目录中则 mybatis.mapper-locations 需设置为 classpath:mybatis/*/*.xml ⑤ DemoService 通过 @Autowired 注解注入 UserMapper ，修改 DemoService 的 test 方法使之调用 UserMapper 的 selectById 方法12345678@Autowiredprivate UserMapper userMapper;@Overridepublic String test() &#123; UserDO user = userMapper.selectById(1); return user.toString();&#125; ⑥ 再次运行 DemoWebApplication 类中的 main 方法启动项目，出现如下报错12345678910111213***************************APPLICATION FAILED TO START***************************Description:Field userMapper in com.example.demo.biz.service.impl.DemoServiceImpl required a bean of type 'com.example.demo.dao.mapper.business.UserMapper' that could not be found.The injection point has the following annotations: - @org.springframework.beans.factory.annotation.Autowired(required=true)Action:Consider defining a bean of type 'com.example.demo.dao.mapper.business.UserMapper' in your configuration. 原因是找不到 UserMapper 类⑦ 在 DemoWebApplication入口类中增加 dao 层包扫描，添加 @MapperScan 注解并设置其值为 com.example.demo.dao.mapper1@MapperScan("com.example.demo.dao.mapper") ⑧ 设置完后重新运行 main 方法，项目正常启动，访问 http://localhost:8080/demo/test 测试接口 五、外部 Tomcat 部署 war 包外部 Tomcat 部署的话，就不能依赖于入口类的 main 函数了，而是要以类似于 web.xml 文件配置的方式来启动 Spring应用上下文。① 在入口类中继承 SpringBootServletInitializer 并实现 configure 方法1234567891011public class DemoWebApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(DemoWebApplication.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(DemoWebApplication.class, args); &#125;&#125; ② 之前在 demo-web 引入了 spring-boot-starter-web 的依赖，该依赖包包含内嵌的 Tomcat 容器，所以直接部署在外部 Tomcat 会冲突报错。这里在 demo-web 层中的 pom 文件中重定义 spring-boot-starter-tomcat 依赖包的「 scope 」即可解决该问题。12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; ③ 声明 demo-web 层的打包方式及最终的包名12345&lt;packaging&gt;war&lt;/packaging&gt;...省略其余部分...&lt;build&gt; &lt;finalName&gt;demo&lt;/finalName&gt;&lt;/build&gt; ④ 此时在 demo-web 层目录执行「 mvn clean install 」即可打出一个名为 demo.war 的包。 六、Maven Profile 多环境打包在日常开发中，通常不止一套环境，如开发环境、测试环境、预发环境、生成环境，而每个环境的配置项可能都不一样，这就需要用到多环境打包来解决这个问题。 ① 在 demo-web 层的 resources 目录中新建 conf 目录，再在其中按照环境创建相应目录，这里创建开发环境「 dev 」及测试环境「 test 」，再将原本的 application.properties 文件分别拷贝一份到两个目录中，根据环境修改其中的配置项，最后删除原本的配置文件。得到目录结构如下：123456|-- resources |-- conf |-- dev | |-- application.properties |-- test |-- application.properties ② 往 demo-web 层的 pom 文件添加 profile 标签1234567891011121314151617&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;profile.env&gt;dev&lt;/profile.env&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;test&lt;/id&gt; &lt;properties&gt; &lt;profile.env&gt;test&lt;/profile.env&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 注：其中 dev 为默认激活的 profile ，如要增加其他环境按照上述步骤操作即可。 ③ 设置打包时资源文件路径1234567891011121314&lt;build&gt; &lt;finalName&gt;demo&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;basedir&#125;/src/main/resources&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;conf/**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/conf/$&#123;profile.env&#125;&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 注：${basedir} 为当前子模块的根目录 ④ 打包时通过「 P 」参数指定 profile1mvn clean install -P test 七、自定义 archetype 模板7.1 什么是 archetype 模板？archetype 是一个 Maven 项目模板工具包，通过 archetype 我们可以快速搭建 Maven 项目。每个模板里其实就是附带不同的依赖和插件。一般在公司私服里都会有属于本公司的一套 archetype 模板，里面有着调试好的项目用到的依赖包和版本号。 7.2 创建 archetype 模板① cd 到项目根目录（即父 pom 文件所在目录）执行 mvn 命令，此时会在项目根目录生成 target 目录，其包含一个名为 generated-sources 的目录1mvn archetype:create-from-project ② 打开「 /target/generated-sources/archetype/src/main/resources/META-INF/maven/ 」目录下的 archetype-metadata.xml 文件，从中清理一些不需要的文件，如 IDEA 的一些文件（.idea、.iml）等。123456789101112131415161718192021222324&lt;fileSet filtered="true" encoding="UTF-8"&gt; &lt;directory&gt;.idea/libraries&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt;&lt;/fileSet&gt;&lt;fileSet filtered="true" encoding="UTF-8"&gt; &lt;directory&gt;.idea/inspectionProfiles&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt;&lt;/fileSet&gt;&lt;fileSet filtered="true" encoding="UTF-8"&gt; &lt;directory&gt;.idea/artifacts&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt;&lt;/fileSet&gt;&lt;fileSet filtered="true" encoding="UTF-8"&gt; &lt;directory&gt;.idea&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt;&lt;/fileSet&gt; ③ 然后 cd target/generated-sources/archetype/，然后执行 install 命令，在本地仓库的根目录生成 archetype-catalog.xml 骨架配置文件1mvn install 文件内容如下：12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;archetype-catalog xsi:schemaLocation="http://maven.apache.org/plugins/maven-archetype-plugin/archetype-catalog/1.0.0 http://maven.apache.org/xsd/archetype-catalog-1.0.0.xsd" xmlns="http://maven.apache.org/plugins/maven-archetype-plugin/archetype-catalog/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt; &lt;archetypes&gt; &lt;archetype&gt; &lt;groupId&gt;com.example.demo&lt;/groupId&gt; &lt;artifactId&gt;demo-archetype&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;description&gt;demo&lt;/description&gt; &lt;/archetype&gt; &lt;/archetypes&gt;&lt;/archetype-catalog&gt; 7.3 使用 archetype 模板到本机的工作目录执行 mvn archetype:generate -DarchetypeCatalog=local 从本地 archeType 模板中创建项目1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253~/Workspace/JAVA $ mvn archetype:generate -DarchetypeCatalog=local[INFO] Scanning for projects...[INFO][INFO] Using the builder org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder with a thread count of 1[INFO][INFO] ------------------------------------------------------------------------[INFO] Building Maven Stub Project (No POM) 1[INFO] ------------------------------------------------------------------------[INFO][INFO] &gt;&gt;&gt; maven-archetype-plugin:3.0.1:generate (default-cli) @ standalone-pom &gt;&gt;&gt;[INFO][INFO] &lt;&lt;&lt; maven-archetype-plugin:3.0.1:generate (default-cli) @ standalone-pom &lt;&lt;&lt;[INFO][INFO] --- maven-archetype-plugin:3.0.1:generate (default-cli) @ standalone-pom ---[INFO] Generating project in Interactive mode[INFO] No archetype defined. Using maven-archetype-quickstart (org.apache.maven.archetypes:maven-archetype-quickstart:1.0)Choose archetype:1: local -&gt; com.example.demo:demo-archetype (demo)Choose a number or apply filter (format: [groupId:]artifactId, case sensitive contains): : 1Define value for property 'groupId': com.orz.testDefine value for property 'artifactId': testDefine value for property 'version' 1.0-SNAPSHOT: :Define value for property 'package' com.orz.test: :Confirm properties configuration:groupId: com.orz.testartifactId: testversion: 1.0-SNAPSHOTpackage: com.orz.test Y: : y[INFO] ----------------------------------------------------------------------------[INFO] Using following parameters for creating project from Archetype: demo-archetype:0.0.1-SNAPSHOT[INFO] ----------------------------------------------------------------------------[INFO] Parameter: groupId, Value: com.orz.test[INFO] Parameter: artifactId, Value: test[INFO] Parameter: version, Value: 1.0-SNAPSHOT[INFO] Parameter: package, Value: com.orz.test[INFO] Parameter: packageInPathFormat, Value: com/orz/test[INFO] Parameter: package, Value: com.orz.test[INFO] Parameter: version, Value: 1.0-SNAPSHOT[INFO] Parameter: groupId, Value: com.orz.test[INFO] Parameter: artifactId, Value: test[INFO] Parent element not overwritten in /Users/linjian/Workspace/JAVA/test/test-biz/pom.xml[INFO] Parent element not overwritten in /Users/linjian/Workspace/JAVA/test/test-common/pom.xml[INFO] Parent element not overwritten in /Users/linjian/Workspace/JAVA/test/test-dao/pom.xml[INFO] Parent element not overwritten in /Users/linjian/Workspace/JAVA/test/test-web/pom.xml[INFO] Project created from Archetype in dir: /Users/linjian/Workspace/JAVA/test[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 01:01 min[INFO] Finished at: 2019-01-15T18:51:31+08:00[INFO] Final Memory: 14M/155M[INFO] ------------------------------------------------------------------------ 上面罗列出了所有可用的模板，首先选择使用哪个模板，这里选择 1 ，其次输入「 groupId 」、「 articleId 」、「 version 」及「 package 」，然后输入「 Y 」确认创建，最终项目创建成功。 八、结语至此 Spring Boot Maven 多模块项目的搭建过程已经介绍完毕，后续会在此基础上继续集成一些中间件。 源码：https://github.com/SymonLin/demo]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建 ES 搜索服务（六）相关性排序优化]]></title>
    <url>%2F2019%2F01%2F14%2Felasticsearch-6%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了搜索结果高亮的实现方法，本篇主要介绍搜索结果相关性排序优化。 二、相关概念2.1 排序默认情况下，返回结果是按照「相关性」进行排序的——最相关的文档排在最前。 2.1.1 相关性排序（默认）在 ES 中相关性评分 由一个浮点数表示，并在搜索结果中通过「 _score 」参数返回，默认是按照 _score 降序排列。 2.1.2 按照字段值排序使用「 sort 」参数实现，可指定一个或多个字段。然而使用 sort 排序过于绝对，它会直接忽略文档本身的相关度，因此仅适合在某些特殊场景使用。 注：如果以字符串字段进行排序，除了索引一份用于全文查询的数据，还需要索引一份原始的未经分析器处理（即 not_analyzed ）的数据。这就需要使用「 fields 」参数实现同一个字段多种索引方式，这里的「索引」是动词相当于「存储」的概念。 2.2 相关性算法ES 5.X 版本将相关性算法由之前的「 TF/IDF 」算法改为了更先进的「 BM25 」算法。 2.2.1 TF/IDF 评分算法 ES版本 &lt; 5 的评分算法，即词频/逆向文档频率。 ① 词频（ Term frequency ）搜索词在文档中出现的频率，频率越高，相关度越高。计算公式如下：$$tf(t\ \ in\ \ d) = \sqrt{frequency}$$搜索词「 t 」在文档「 d 」的词频「 tf 」是该词在文档中出现次数的平方根。 ② 逆向文档频率（ Inverse document frequency ）搜索词在索引（单个分片）所有文档里出现的频率，频率越高，相关度越低。用人话描述就是「物以稀为贵」，计算公式如下：$$idf(t) = 1 + log \frac{docCount}{docFreq + 1}$$搜索词「 t 」的逆向文档频率「 idf 」是索引中的文档总数除以所有包含该词的文档数，然后求其对数。 ③ 字段长度归一值（ Field length norm ）字段的长度，字段越短，相关度越高。计算公式如下：$$norm(d) = \frac{1}{\sqrt{numTerms}}$$字段长度归一值「 norm 」是字段中词数平方根的倒数。 注：前面公式中提到的「文档」实际上是指文档里的某个字段 2.2.2 BM25 评分算法 ES版本 &gt;= 5 的评分算法；BM25 的 BM 是缩写自 Best Match， 25 貌似是经过 25 次迭代调整之后得出的算法。它也是基于 TF / IDF 算法进化来的。 对于给定查询语句「Q」，其中包含关键词「$q_{1}$,…$q_{n}$」，那么文档「D」的 BM25 评分计算公式如下：$$score(D,Q) = \sum_{i=1}^NIDF(q_{i})\ ·\ \frac{f(q_{i},D)\ ·\ (k_{1}+1)}{f(q_{i},D)+k_{1}\ ·\ (1-b+b\ ·\ \frac{|D|}{avgdl})}$$这个公式看起来很唬人，尤其是那个求和符号，不过分解开来还是比较好理解的。 总体而言，主要还是分三部分，TF - IDF - Document Length IDF 的计算公式调整为如下所示，其中N 为文档总数， $n(q_{i})$ 为包含搜索词 $q_{i}$ 的文档数。$$IDF(q_{i}) = 1 + log\frac{N-n(q_{i})+0.5}{n(q_{i})+0.5}$$ $f(q_{i},D)$ 为搜索词 $q_{i}$ 在文档 D 中的「 TF 」，| D | 是文档的长度，avgdl 是平均文档长度。先不看 IDF 和 Document Length 的部分， 则公式变为 TF * ($k_{1}$ + 1) / (TF + $k_{1}$)，相比传统的 TF/IDF 而言，BM25 抑制了 TF 对整体评分的影响程度，虽然同样都是增函数，但是 BM25 中，TF 越大，带来的影响无限趋近于 ($k_{1}$ + 1)，这里 $k_{1}$ 值通常取 [1.2, 2.0]，而传统的 TF/IDF 则会没有临界点的无限增长。 至于文档长度 | D | 的影响，可以看到在命中搜索词的情况下，文档越短，相关性越高，具体影响程度又可以由公式中的 b 来调整，当设值为 0 的时候，就跟将 norms 设置为 false 一样，忽略文档长度的影响。 最后再对所有搜索词的计算结果求和，就是 ES5 中一般查询的得分了。 三、实际案例3.1 现实需求要求搜索文章时，搜索词出现在标题时的权重要比出现在内容中高，同时要考虑「引用次数」对最终排序的影响。 3.2 实现方法3.2.1 调整搜索字段权重通过调整字段的 boost 参数实现自定义权重，此处将标题的权重调整为内容的两倍。123456789101112private SearchQuery getKnowledgeSearchQuery(KnowledgeSearchParam param) &#123; ...省略其余部分... BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); boolQuery.must(QueryBuilders.termQuery("isDeleted", IsDeletedEnum.NO.getKey())); boolQuery.should(QueryBuilders.matchQuery(knowledgeTitleFieldName, param.getKeyword()).boost(2.0f)); boolQuery.should(QueryBuilders.matchQuery(knowledgeContentFieldName, param.getKeyword())); return new NativeSearchQueryBuilder() .withPageable(pageable) .withQuery(boolQuery) .withHighlightFields(knowledgeTitleField, knowledgeContentField) .build();&#125; 3.2.2 按引用次数提升权重这里通过 function score 实现重打分操作。根据上面的需求，我们将使用 field value factor 函数指定「 referenceCount 」字段计算分数并与 _score 相加作为最终评分进行排序。1234567891011121314151617private SearchQuery getKnowledgeSearchQuery(KnowledgeSearchParam param) &#123; ...省略其余部分... // 引用次数更多的知识点排在靠前的位置 // 对应的公式为：_score = _score + log (1 + 0.1 * referenceCount) ScoreFunctionBuilder scoreFunctionBuilder = ScoreFunctionBuilders .fieldValueFactorFunction("referenceCount") .modifier(FieldValueFactorFunction.Modifier.LN1P) .factor(0.1f); FunctionScoreQueryBuilder functionScoreQuery = QueryBuilders .functionScoreQuery(boolQuery, scoreFunctionBuilder) .boostMode(CombineFunction.SUM); return new NativeSearchQueryBuilder() .withPageable(pageable) .withQuery(functionScoreQuery) .withHighlightFields(knowledgeTitleField, knowledgeContentField) .build();&#125; 上述的 function score 是 ES 用于处理文档分值的 DSL（领域专用语言），它预定义了一些计算分值的函数： ① weight为每个文档应用一个简单的权重提升值：当 weight 为 2 时，最终结果为 2 * _score ② field_value_factor通过文档中某个字段的值计算出一个分数且使用该值修改 _score，具有以下属性： 属性 描述 field 指定字段名 factor 对字段值进行预处理，乘以指定的数值，默认为 1 modifier 将字段值进行加工，默认为 none boost_mode 控制函数与 _score 合并的结果，默认为 multiply ③ random_score为每个用户都使用一个随机评分对结果排序，可以实现对于用户的个性化推荐。 ④ 衰减函数提供一个更复杂的公式，描述了这样一种情况：对于一个字段，它有一个理想值，而字段实际的值越偏离这个理想值就越不符合期望。具有以下属性： 属性 描述 origin（原点） 该字段的理想值，满分 1.0 offset（偏移量） 与原点相差在偏移量之内的值也可以得到满分 scale（衰减规模） 当值超出原点到偏移量这段范围，它所得的分数就开始衰减，衰减规模决定了分数衰减速度的快慢 decay（衰减值） 该字段可以被接受的值，默认为 0.5 ⑤ script_score支持自定义脚本完全控制评分计算 3.2.3 理解评分标准通过JAVA API 实现相关功能后，输出评分说明可以帮助我们更好的理解评分过程以及后续调整算法参数。 ① 首先定义一个打印搜索结果的方法，设置 explain = true 即可输出 explanation 。1234567891011121314151617181920public void debugSearchQuery(SearchQuery searchQuery, String indexName) &#123; SearchRequestBuilder searchRequestBuilder = elasticsearchTemplate.getClient().prepareSearch(indexName).setTypes(indexName); searchRequestBuilder.setSearchType(SearchType.DFS_QUERY_THEN_FETCH); searchRequestBuilder.setFrom(0).setSize(10); searchRequestBuilder.setExplain(true); searchRequestBuilder.setQuery(searchQuery.getQuery()); SearchResponse searchResponse; try &#123; searchResponse = searchRequestBuilder.execute().get(); long totalCount = searchResponse.getHits().getTotalHits(); log.info("总条数 totalCount:" + totalCount); //遍历结果数据 SearchHit[] hitList = searchResponse.getHits().getHits(); for (SearchHit hit : hitList) &#123; log.info("SearchHit hit explanation:&#123;&#125;\nsource:&#123;&#125;", hit.getExplanation().toString(), hit.getSourceAsString()); &#125; &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125;&#125; ② 之后调用接口，其 explanation 结果展示如下：12345678910111213141516171819202122232419.491358 = sum of 19.309036 = sum of: 19.309036 = sum of: 19.309036 = weight(knowledgeTitle.pinyin:test in 181) [PerFieldSimilarity], result of: 19.309036 = score(doc=181,freq=1.0 = termFreq=1.0), product of: 2.0 = boost 6.2461066 = idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from: 2.0 = docFreq 1289.0 = docCount 1.5456858 = tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from: 1.0 = termFreq=1.0 1.2 = parameter k1 0.75 = parameter b 29.193172 = avgFieldLength 4.0 = fieldLength 0.0 = match on required clause, product of: 0.0 = # clause 1.0 = isDeleted:[0 TO 0], product of: 1.0 = boost 1.0 = queryNorm 0.18232156 = min of: 0.18232156 = field value function: ln1p(doc['referenceCount'].value * factor=0.1) 3.4028235E38 = maxBoost 其中 idf = 6.2461066，tfNorm = 1.5456858，boost = 2.0，由于此时只有一个搜索字段，因此 score = idf * tfNorm * boost = 19.309036；与此同时 field value function = 0.18232156；最终得分 sum = 19.309036 + 0.18232156 = 19.491358 。 四、结语至此一个简单需求的相关性排序优化已经实现完毕，由于业务的关系暂时未涉及其他复杂的场景，所以此篇仅仅作为一个入门介绍。 五、参考博文 通过Function Score Query优化Elasticsearch搜索结果(综合排序) Elasticsearch 5.X(Lucene 6) 的 BM25 相关度算法]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建 ES 搜索服务（五）搜索结果高亮]]></title>
    <url>%2F2019%2F01%2F08%2Felasticsearch-5%2F</url>
    <content type="text"><![CDATA[一、前言在实际使用中搜索结果中的关键词前端通常会以特殊形式展示，比如标记为红色使人一目了然。我们可以通过 ES 提供的高亮功能实现此效果。 二、代码实现前文查询是通过一个继承 ElasticsearchRepository 的接口实现的，但是如果要实现高亮，这种方式就满足不了了，这里我们需要通过 ElasticsearchTemplate 来完成。 2.1 注入 ElasticsearchTemplate① ElasticsearchTemplate 类简介123public class ElasticsearchTemplate implements ElasticsearchOperations, ApplicationContextAware &#123; ...省略其余部分...&#125; 从上述源码中可以看到 ElasticsearchTemplate 实现了 ApplicationContextAware 接口，表明这个类是被 Spring 管理的，可以直接注入使用。 ② 业务实现类注入 ElasticsearchTemplate12@Autowiredprivate ElasticsearchTemplate elasticsearchTemplate; 2.2 查询对象指定高亮字段 在构建查询对象时需要指定高亮字段，通过 withHighlightFields 方法设置。 123456789101112131415161718private SearchQuery getKnowledgeSearchQuery(KnowledgeSearchParam param) &#123; Pageable pageable = PageRequest.of(param.getStart() / param.getSize(), param.getSize()); String knowledgeTitleFieldName = "knowledgeTitle"; String knowledgeContentFieldName = "knowledgeContent"; String preTags = "&lt;span style=\"color:#F56C6C\"&gt;"; String postTags = "&lt;/span&gt;"; HighlightBuilder.Field knowledgeTitleField = new HighlightBuilder.Field(knowledgeTitleFieldName).preTags(preTags).postTags(postTags); HighlightBuilder.Field knowledgeContentField = new HighlightBuilder.Field(knowledgeContentFieldName).preTags(preTags).postTags(postTags); BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery(); queryBuilder.must(QueryBuilders.termQuery("isDeleted", IsDeletedEnum.NO.getKey())); queryBuilder.should(QueryBuilders.matchQuery(knowledgeTitleFieldName, param.getKeyword())); queryBuilder.should(QueryBuilders.matchQuery(knowledgeContentFieldName, param.getKeyword())); return new NativeSearchQueryBuilder() .withPageable(pageable) .withQuery(queryBuilder) .withHighlightFields(knowledgeTitleField, knowledgeContentField) .build();&#125; 2.3 自定义 ResultMapper ResultMapper 是用于将 ES 文档转换成 Java 对象的映射类，因为 Spring Data Elasticsearch 默认的的映射类 DefaultResultMapper 不支持高亮，因此，我们需要自定义一个 ResultMapper 。 完整代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576@Slf4j@Componentpublic class HighlightResultHelper implements SearchResultMapper &#123; private static ObjectMapper objectMapper = new ObjectMapper(); static &#123; objectMapper.setVisibility(JsonMethod.FIELD, JsonAutoDetect.Visibility.ANY); objectMapper.configure(SerializationConfig.Feature.INDENT_OUTPUT, true); objectMapper.configure(DeserializationConfig.Feature.FAIL_ON_UNKNOWN_PROPERTIES, false); &#125; private static final Pattern SUB_FIELD_PATTERN = Pattern.compile("\\..*"); private static final String HIGHLIGHT_FIELD_SUFFIX = "Highlight"; @Override public &lt;T&gt; AggregatedPage&lt;T&gt; mapResults(SearchResponse response, Class&lt;T&gt; clazz, Pageable pageable) &#123; long totalHits = response.getHits().getTotalHits(); List&lt;T&gt; list = Lists.newArrayList(); // 获取搜索结果 SearchHits hits = response.getHits(); for (SearchHit searchHit : hits) &#123; if (hits.getHits().length &lt;= 0) &#123; continue; &#125; // 获取高亮字段Map Map&lt;String, HighlightField&gt; highlightFields = searchHit.getHighlightFields(); // 通过jackson将json字符串转化为对象 T item = jsonStrToObject(searchHit.getSourceAsString(), clazz); if (Objects.isNull(item)) &#123; continue; &#125; // 遍历高亮字段Map，将高亮字段key转化为原始字段名（title.pinyin -&gt; title），拼接高亮文本并与原始字段名组装为一个Map Map&lt;String, String&gt; highlightFieldMap = Maps.newHashMap(); for (Map.Entry&lt;String, HighlightField&gt; highlightField : highlightFields.entrySet()) &#123; String key = SUB_FIELD_PATTERN.matcher(highlightField.getKey()).replaceAll(Constants.BLANK) + HIGHLIGHT_FIELD_SUFFIX; HighlightField value = highlightField.getValue(); Text[] fragments = value.getFragments(); StringBuilder sb = new StringBuilder(); for (Text text : fragments) &#123; sb.append(text); &#125; highlightFieldMap.put(key, sb.toString()); &#125; // 通过反射将高亮文本赋值到原始字段对应的高亮字段中 try &#123; Field[] fields = clazz.getDeclaredFields(); for (Field field : fields) &#123; if (!field.getName().contains(HIGHLIGHT_FIELD_SUFFIX)) &#123; continue; &#125; field.setAccessible(true); if (highlightFieldMap.containsKey(field.getName())) &#123; field.set(item, highlightFieldMap.get(field.getName())); &#125; else &#123; field.set(item, searchHit.getSource().get(field.getName().replace(HIGHLIGHT_FIELD_SUFFIX, Constants.BLANK))); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; list.add(item); &#125; return new AggregatedPageImpl&lt;&gt;(list, pageable, totalHits); &#125; private &lt;T&gt; T jsonStrToObject(String json, Class&lt;T&gt; cls) &#123; try &#123; return objectMapper.readValue(json, cls); &#125; catch (IOException e) &#123; log.error("json cant be objectTranslate to object,&#123;&#125;", json); return null; &#125; &#125;&#125; 2.4 获取返回结果① 返回对象增加高亮字段12345678910@Data@Document(indexName = "knowledge", type = "knowledge")public class KnowledgeDO &#123; ...省略其余部分... private String knowledgeTitleHighlight; private String knowledgeContentHighlight;&#125; ② 业务实现类注入 HighlightResultHelper12@Autowiredprivate HighlightResultHelper highlightResultHelper; ③ 获取分页结果由前文的 knowledgeRepository.search 改为 elasticsearchTemplate.queryForPage 实现，查询时指定 highlightResultHelper1Page&lt;KnowledgeDO&gt; page = elasticsearchTemplate.queryForPage(searchQuery, KnowledgeDO.class, highlightResultHelper); 注：测试结果展示 12345678910[ &#123; "id": 850, "knowledgeTitle": "小儿腺样体肥大的孩子宜多吃什么？", "knowledgeTitleHighlight": "小儿腺样体肥大的孩子宜多吃什么？", "knowledgeContent": "1、饮食中要停掉一切寒凉的食物，只吃性平、性温的食物，如猪肉、鸡肉、牛肉、鸽肉、鹌鹑、鳝鱼、泥鳅、青菜、白菜、包菜、黄豆芽、土豆、韭菜、胡萝卜(一周2次)等，夏天再增加四季豆、豇豆、黄瓜、西红柿、藕、芹菜、花菜、各种菌类(菌类也偏凉适合夏天吃)，水果吃新鲜时令的水果，5月份以后，新鲜水果上市了。可以吃草莓、桃子、葡萄、樱桃，秋天可以吃苹果、梨子、桔子等。\n2、每周吃2-3次红烧鳝鱼或喝鳝鱼汤，鳝鱼与其它鱼类不同，补血、补肾、抗过敏的作用明显，但不易上火，补而不燥。每周吃2次海虾，一次10只左右，7岁左右的孩子可以一次半斤，海虾就是鸡尾虾或对虾，补肾阳的作用明显，可以用来治疗慢性扁桃体炎、慢性鼻炎、慢性咽炎，与河虾的功效完全不一样。", "knowledgeContentHighlight": "1、饮食中要停掉一切寒凉的食物，只吃性平、性温的食物，如猪肉、鸡肉、牛肉、鸽肉、鹌鹑、鳝鱼、泥鳅、青菜、白菜、包菜、黄豆芽、土豆、韭菜、胡萝卜(一周2次)等，夏天再增加四季豆、豇豆、黄瓜、&lt;span style=\"color:#F56C6C\"&gt;西红柿&lt;/span&gt;、藕", "referenceCount": 0 &#125;] 三、结语至此搜索结果高亮已经实现完毕，下一篇将介绍相关度排序优化。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建 ES 搜索服务（四）拼音搜索]]></title>
    <url>%2F2019%2F01%2F07%2Felasticsearch-4%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了 ES 的同义词搜索，使我们的搜索更强大了，然而这还远远不够，在实际使用中还可能希望搜索「fanqie」能将包含「番茄」的结果也罗列出来，这就涉及到拼音搜索了，本篇将介绍如何具体实现。 二、安装 ES 拼音插件2.1 拼音插件简介 GitHub 地址：https://github.com/medcl/elasticsearch-analysis-pinyin 2.2 安装步骤① 进入 ES 的 bin 目录1$ cd /usr/local/elasticsearch/bin/ ② 通过 elasticsearch-plugin 命令安装 pinyin 插件1$ ./elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-pinyin/releases/download/v5.5.3/elasticsearch-analysis-pinyin-5.5.3.zip ③ 安装成功后会在 plugins 目录出现 analysis-pinyin 文件夹 三、自定义分析器要使用「拼音插件」需要在创建索引时使用「自定义模板」并在自定义模板中「自定义分析器」。 3.1 具体配置① 在上篇新建的「 yb_knowledge.json 」模板中修改「 setting 」配置，往其中添加自定义分析器1234567891011121314151617181920212223242526"analysis": &#123; "filter": &#123; ...省略其余部分... "pinyin_filter":&#123; "type": "pinyin", "keep_first_letter": true, "keep_separate_first_letter": false, "keep_full_pinyin": true, "keep_joined_full_pinyin": true, "none_chinese_pinyin_tokenize": false, "keep_joined_full_pinyin": true, "remove_duplicated_term": true, "keep_original": true, "limit_first_letter_length": 50, "lowercase": true &#125; &#125;, "analyzer": &#123; ...省略其余部分... "ik_synonym_pinyin": &#123; "type": "custom", "tokenizer": "ik_smart", "filter": ["synonym_filter","pinyin_filter"] &#125; &#125;&#125; 自定义分析器说明： 首先声明一个新「 token filter 」—— 「 pinyin_filter 」，其中 type 为 pinyin 即拼音插件，其余字段详见 GitHub 项目说明。 其次声明一个新 「analyzer」—— 「ik_synonym_pinyin」，其中 type 为 custom 即自定义类型， tokenizer 为 ik_smart 即使用 ik 分析器的 ik_smart 分词模式， filter 为要使用的词过滤器，可以使用多个，这里使用了上述定义的 pinyin_filter 以及前篇的 synonym_filter 。 ② 与此同时修改「 mappings 」中的 properties 配置，往「 knowledgeTitle 」及「 knowledgeContent 」这两个搜索字段里添加 fields 参数，它支持以不同方式对同一字段做索引，将原本的简单映射转化为多字段映射，此处设置一个名为「 pinyin 」的嵌套字段且使用上述自定义的「 ik_synonym_pinyin 」作为分析器。12345678910111213141516171819202122232425262728"mappings": &#123; "knowledge": &#123; ...省略其余部分... "properties": &#123; ...省略其余部分... "knowledgeTitle": &#123; "type": "text", "analyzer": "ik_synonym_max", "fields":&#123; "pinyin": &#123; "type":"text", "analyzer": "ik_synonym_pinyin" &#125; &#125; &#125;, "knowledgeContent": &#123; "type": "text", "analyzer": "ik_synonym_max", "fields":&#123; "pinyin": &#123; "type":"text", "analyzer": "ik_synonym_pinyin" &#125; &#125; &#125; &#125; &#125;&#125; ③ 最后删除先前创建的 yb_knowledge 索引并重启 Logstash 注：重建索引后可以通过「_analyze」测试分词结果 12345curl -XGET http://localhost:9200/yb_knowledge/_analyze&#123; "analyzer":"ik_synonym_pinyin", "text":"番茄"&#125; 注：在添加了同义词「番茄、西红柿、圣女果」的基础上分词结果如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123&#123; "tokens": [ &#123; "token": "fan", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 0 &#125;, &#123; "token": "番茄", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 0 &#125;, &#123; "token": "fanqie", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 0 &#125;, &#123; "token": "fq", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 0 &#125;, &#123; "token": "qie", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 1 &#125;, &#123; "token": "xi", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 2 &#125;, &#123; "token": "hong", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 3 &#125;, &#123; "token": "shi", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 4 &#125;, &#123; "token": "西红柿", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 4 &#125;, &#123; "token": "xihongshi", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 4 &#125;, &#123; "token": "xhs", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 4 &#125;, &#123; "token": "sheng", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 5 &#125;, &#123; "token": "nv", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 6 &#125;, &#123; "token": "guo", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 7 &#125;, &#123; "token": "圣女果", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 7 &#125;, &#123; "token": "shengnvguo", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 7 &#125;, &#123; "token": "sng", "start_offset": 0, "end_offset": 2, "type": "SYNONYM", "position": 7 &#125; ]&#125; 四、结语至此拼音搜索已经实现完毕，最近两篇都是有关 ES 插件以及 Logstash 自定义模板的配置，没有涉及具体的 JAVA 代码实现，下一篇将介绍如何通过 JAVA API 实现搜索结果高亮。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建 ES 搜索服务（三）同义词搜索]]></title>
    <url>%2F2018%2F12%2F28%2Felasticsearch-3%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了 ES 的基础搜索，能满足我们基本的需求，然而在实际使用中还可能希望搜索「番茄」能将包含「西红柿」的结果也罗列出来，本篇将介绍如何实现同义词之间的搜索。 二、安装 ES 同义词插件2.1 同义词插件简介 GitHub 地址：https://github.com/ginobefun/elasticsearch-dynamic-synonym 定时从 MySQL 中获取自定义词库，支持「扩展词」及「停用词」 2.2 安装步骤参考 GitHub 中的项目说明 三、自定义分析器要使用「同义词插件」需要在创建索引时使用「自定义模板」并在自定义模板中「自定义分析器」。 3.1 相关概念① 字符过滤器（character filter）② 分词器（tokenizer）③ 词过滤器（token filter） 自定义分析器官方文档：https://www.elastic.co/guide/cn/elasticsearch/guide/current/custom-analyzers.html 3.2 具体配置① 在上篇新建的「 yb_knowledge.json 」模板中修改「 setting 」配置，往其中添加自定义分析器12345678910111213141516171819202122232425262728"analysis": &#123; "filter": &#123; "synonym_filter": &#123; "type": "dynamic-synonym", "expand": true, "ignore_case": true, "interval": 30, "tokenizer": "ik_max_word", "db_url": "jdbc:mysql://localhost:3306/elasticsearch?user=es_user&amp;password=es_pwd&amp;useUnicode=true&amp;characterEncoding=UTF8" &#125; &#125;, "analyzer": &#123; "ik_synonym_max": &#123; "type": "custom", "tokenizer": "ik_max_word", "filter": [ "synonym_filter" ] &#125;, "ik_synonym_smart": &#123; "type": "custom", "tokenizer": "ik_smart", "filter": [ "synonym_filter" ] &#125; &#125;&#125; 自定义分析器说明： 首先声明一个新「 token filter 」—— 「 synonym_filter 」，其中 type 为 dynamic-synonym 即动态同义词插件， interval 为 定时同步频率（单位为秒）， db_url 为词库的数据库地址。 其次声明一个新 「analyzer」—— 「ik_synonym_max」，其中 type 为 custom 即自定义类型， tokenizer 为 ik_max_word 即使用 ik 分析器的 ik_max_word 分词模式， filter 为要使用的词过滤器，可以使用多个，这里使用了上述定义的 synonym_filter 。 同上继续声明一个以 ik 分析器的 ik_smart 分词模式作为分词器的分析器。 ② 与此同时修改「 mappings 」中的 properties 配置，将「 knowledgeTitle 」及「 knowledgeContent 」这两个字段使用的分析器更换为上述自定义的「 ik_synonym_max 」12345678910111213141516"mappings": &#123; "knowledge": &#123; ...省略其余部分... "properties": &#123; ...省略其余部分... "knowledgeTitle": &#123; "type": "text", "analyzer": "ik_synonym_max" &#125;, "knowledgeContent": &#123; "type": "text", "analyzer": "ik_synonym_max" &#125; &#125; &#125;&#125; ③ 最后删除先前创建的 yb_knowledge 索引并重启 Logstash 注：重建索引后可以通过「_analyze」测试分词结果 ④ 原本在索引中已存在的数据不受同义词动态更新的影响，可以通过以下命令手动更新1curl -XPOST 'http://localhost:9200/yb_knowledge/_update_by_query?conflicts=proceed' 四、结语至此同义词搜索已经实现完毕，后续将继续介绍其他附加功能，如拼音搜索以及搜索结果高亮等。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建 ES 搜索服务（二）基础搜索]]></title>
    <url>%2F2018%2F12%2F27%2Felasticsearch-2%2F</url>
    <content type="text"><![CDATA[一、前言上篇介绍了 ES 的基本概念及环境搭建，本篇将结合实际需求介绍整个实现过程及核心代码。 二、安装 ES ik 分析器插件2.1 ik 分析器简介 GitHub 地址：https://github.com/medcl/elasticsearch-analysis-ik 提供两种分词模式：「 ik_max_word 」及「 ik_smart 」 分词模式 描述 ik_max_word 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合 ik_smart 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌” 2.2 安装步骤① 进入 ES 的 bin 目录1$ cd /usr/local/elasticsearch/bin/ ② 通过 elasticsearch-plugin 命令安装 ik 插件1$ ./elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.5.3/elasticsearch-analysis-ik-5.5.3.zip ③ 安装成功后会在 plugins 目录出现 analysis-ik 文件夹 三、数据同步3.1 方案设计通过 Logstash 实现 MySQL 数据库中的数据同步到 ES 中，第一次全量同步，后续每分钟增量同步一次 3.2 实现步骤3.2.1 安装 logstash-input-jdbc 插件① 进入 Logstash 的 bin 目录1$ cd /usr/local/logstash/bin/ ② 使用 logstash-plugin 命令安装 logstash-input-jdbc 插件1$ ./logstash-plugin install logstash-input-jdbc 3.2.2 MySQL 同步数据配置① 首先在 Logstash 安装目录中新建「MySQL 输入数据源」相关目录 /usr/local/logstash/mysql &gt; MySQL 输入数据源目录/usr/local/logstash/mysql/config &gt; 配置文件目录/usr/local/logstash/mysql/metadata &gt; 追踪字段记录文件目录/usr/local/logstash/mysql/statement &gt; SQL 脚本目录 ② 其次上传「MySQL JDBC 驱动」至 /usr/local/logstash/mysql 目录中 mysql-connector-java-5.1.40.jar ③ 然后新建「 SQL 脚本文件」，即 /usr/local/logstash/mysql/statement 目录中新建 yb_knowledge.sql 文件，内容如下：12345678910111213SELECT id, create_time AS createTime, modify_time AS modifyTime, is_deleted AS isDeleted, knowledge_title AS knowledgeTitle, author_name AS authorName, knowledge_content AS knowledgeContent, reference_count AS referenceCountFROM yb_knowledgeWHERE modify_time &gt;= :sql_last_value ④ 之后再新建「配置文件」，即 /usr/local/logstash/mysql/config 目录中新建 yb_knowledge.conf 文件，内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849input &#123; jdbc &#123; jdbc_connection_string =&gt; "jdbc:mysql://192.168.1.192:3306/yibao_health" jdbc_user =&gt; "yibao" jdbc_password =&gt; "yibao0415" jdbc_driver_library =&gt; "/usr/local/logstash/mysql/mysql-connector-java-5.1.40.jar" jdbc_driver_class =&gt; "com.mysql.jdbc.Driver" jdbc_paging_enabled =&gt; "true" jdbc_page_size =&gt; "50000" jdbc_default_timezone =&gt; "UTC" lowercase_column_names =&gt; false # 使用其它字段追踪，而不是用时间 use_column_value =&gt; true # 追踪的字段 tracking_column =&gt; "modifyTime" record_last_run =&gt; true # 上一个sql_last_value值的存放文件路径, 必须要在文件中指定字段的初始值 last_run_metadata_path =&gt; "/usr/local/logstash/mysql/metadata/yb_knowledge.txt" # 执行的sql文件路径+名称 statement_filepath =&gt; "/usr/local/logstash/mysql/statement/yb_knowledge.sql" # 设置监听间隔 各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新 schedule =&gt; "* * * * *" # 索引类型 type =&gt; "knowledge" &#125;&#125;filter &#123; json &#123; source =&gt; "message" remove_field =&gt; ["message"] &#125;&#125;output &#123; if [type] == "knowledge" &#123; elasticsearch &#123; hosts =&gt; ["localhost:9200"] index =&gt; "yb_knowledge" document_id =&gt; "%&#123;id&#125;" &#125; &#125; stdout &#123; # JSON格式输出 codec =&gt; json_lines &#125;&#125; ⑤ 进入 Logstash 的 bin 目录启动，启动时既可指定单个要加载的 conf 文件，也可以指定整个 config 目录1$ ./logstash -f ../mysql/config/yb_knowledge.conf 注：启动 Logstash 时，不管有多少个配置文件最后都会编译成一个文件，也就是说无论有多少个 input 或 output ，最终只有一个 pipeline注：每分钟的 0 秒 Logstash 会自动去同步数据 elasticsearch-head 中可看到最终结果如下： 3.2.3 自定义模板配置此时建立的索引中字符串字段是用的默认分析器 「standard」，会把中文拆分成一个个汉字，这显然不满足我们的需求，所以需要自定义配置以使用 ik 分析器① 首先在 Logstash 安装目录中新建「自定义模板文件」目录 /usr/local/logstash/template &gt; 自定义模板文件目录 ② 其次在该目录中新建 yb_knowledge.json 模板文件，内容如下：12345678910111213141516171819202122232425262728293031323334353637&#123; "template": "yb_knowledge", "settings": &#123; "index.refresh_interval": "5s", "number_of_shards": "1", "number_of_replicas": "1" &#125;, "mappings": &#123; "knowledge": &#123; "_all": &#123; "enabled": false, "norms": false &#125;, "properties": &#123; "@timestamp": &#123; "type": "date", "include_in_all": false &#125;, "@version": &#123; "type": "keyword", "include_in_all": false &#125;, "knowledgeTitle": &#123; "type": "text", "analyzer": "ik_max_word" &#125;, "knowledgeContent": &#123; "type": "text", "analyzer": "ik_max_word" &#125; &#125; &#125; &#125;, "aliases": &#123; "knowledge": &#123;&#125; &#125;&#125; ③ 然后修改 yb_knowledge.conf 文件中的 output 插件，指定要使用的模板文件路径12345678910if [type] == "knowledge" &#123; elasticsearch &#123; hosts =&gt; ["localhost:9200"] index =&gt; "yb_knowledge" document_id =&gt; "%&#123;id&#125;" template_overwrite =&gt; true template =&gt; "/usr/local/logstash/template/yb_knowledge.json" template_name =&gt; "yb_knowledge" &#125; &#125; ④ 之后停止 Logstash 并删除 metadata 目录下 sql_last_value 的存放文件1$ rm -rf /usr/local/logstash/mysql/metadata/yb_knowledge.txt ⑤ 最后删除先前创建的 yb_knowledge 索引并重启 Logstash 注：重建索引后可以通过「_analyze」测试分词结果 3.2.4 自动重载配置文件为了可以自动检测配置文件的变动和自动重新加载配置文件，需要在启动的时候使用以下命令1$ ./logstash -f ../mysql/config/ --config.reload.automatic 默认检测配置文件的间隔时间是 3 秒，可以通过以下命令改变1--config.reload.interval &lt;second&gt; 配置文件自动重载工作原理： 检测到配置文件变化 通过停止所有输入停止当前 pipline （即管道） 用新的配置创建一个新的 pipeline 检查配置文件语法是否正确 检查所有的输入和输出是否可以初始化 检查成功使用新的 pipeline 替换当前的 pipeline 检查失败，使用旧的继续工作 在重载过程中， Logstash 进程没有重启 注：自动重载配置文件不支持 stdin 这种输入类型 四、代码实现以下代码实现基于 Spring Boot 2.0.4，通过 Spring Data Elasticsearch 提供的 API 操作 ES 4.1 搭建 Spring Boot 项目 Spring Boot 项目实战（一）多模块项目搭建 4.2 引入核心依赖包1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt; 4.3 添加 Spring Boot ES 相关配置项在 application.properties 文件中添加 ES 相关配置项123spring.data.elasticsearch.cluster-name = compassspring.data.elasticsearch.cluster-nodes = xxx.xxx.xxx.xxx:9300spring.data.elasticsearch.repositories.enabled = true 4.4 核心代码Spring Data Elasticsearch 提供了类似数据库操作的 repository 接口，可以使我们像操作数据库一样操作 ES① 定义实体123456789101112131415161718192021@Data@Document(indexName = "knowledge", type = "knowledge")public class KnowledgeDO &#123; @Id private Integer id; private Integer isDeleted; private java.time.LocalDateTime createTime; private java.time.LocalDateTime modifyTime; private String knowledgeTitle; private String authorName; private String knowledgeContent; private Integer referenceCount;&#125; ② 定义 repository 接口12public interface KnowledgeRepository extends ElasticsearchRepository&lt;KnowledgeDO, Integer&gt; &#123;&#125; ③ 构建查询对象12345678910111213private SearchQuery getKnowledgeSearchQuery(KnowledgeSearchParam param) &#123; Pageable pageable = PageRequest.of(param.getStart() / param.getSize(), param.getSize()); BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); // 使用 filter 比使用 must query 性能要好 boolQuery.filter(QueryBuilders.termQuery("isDeleted", IsDeletedEnum.NO.getKey())); // 多字段查询 MultiMatchQueryBuilder multiMatchQuery = QueryBuilders.multiMatchQuery(param.getKeyword(), "knowledgeTitle", "knowledgeContent"); boolQuery.must(multiMatchQuery); return new NativeSearchQueryBuilder() .withPageable(pageable) .withQuery(boolQuery) .build();&#125; 注：上述查询类似于 MySQL 中的 select 语句「select * from yb_knowledge where is_deleted = 0 and (knowledge_title like ‘%keyword%’ or knowledge_content like ‘%keyword%’)」 ④ 获取返回结果12SearchQuery searchQuery = getKnowledgeSearchQuery(param);Page&lt;KnowledgeDO&gt; page = knowledgeRepository.search(searchQuery); 注：最终结果默认会按照相关性得分倒序排序，即每个文档跟查询关键词的匹配程度 五、结语至此一个简易的搜索服务已经实现完毕，后续将继续介绍一些附加功能，如同义词搜索、拼音搜索以及搜索结果高亮等 六、其它6.1 注意事项① 在 Logstash 的 config 目录执行启动命令时会触发以下错误，所以请移步 bin 目录执行启动命令1ERROR Unable to locate appender "$&#123;sys:ls.log.format&#125;_console" for logger config "root" ② Logstash 中 last_run_metadata_path 文件中保存的 sql_last_value 值是最新一条记录的 tracking_column 值，而不是所有记录中最大的 tracking_column 值③ 当 MySQL 中字段类型为 tinyint(1) 时，同步到 ES 后该字段会转化成布尔类型，改为 tinyint(4) 可避免该问题 6.2 如何使 ES 中的字段名与 Java 实体字段名保持一致？Java 实体字段通常是小驼峰形式命名，而我们数据库表字段都是下划线形式的，所以需要将两者建立映射关系，方法如下：① 修改 statement_filepath 的 SQL 脚本，表字段用 AS 设置成小驼峰式的别名，与 Java 实体字段名保持一致② Logstash 配置文件中的 jdbc 配置还需要加一个配置项 lowercase_column_names =&gt; false ，否则在 ES中字段名默认都是以小写形式存储，不支持驼峰形式 6.3 Logstash 自定义模板详解① 第一次启动 Logstash 时默认会生成一个名叫 「logstash」 的模板到 ES 里，可以通过以下命令查看1curl -XGET 'http://localhost:9200/_template/logstash' 注：默认模板内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&#123; "logstash": &#123; "order": 0, "version": 50001, "template": "logstash-*", "settings": &#123; "index": &#123; "refresh_interval": "5s" &#125; &#125;, "mappings": &#123; "_default_": &#123; "dynamic_templates": [ &#123; "message_field": &#123; "path_match": "message", "mapping": &#123; "norms": false, "type": "text" &#125;, "match_mapping_type": "string" &#125; &#125;, &#123; "string_fields": &#123; "mapping": &#123; "norms": false, "type": "text", "fields": &#123; "keyword": &#123; "ignore_above": 256, "type": "keyword" &#125; &#125; &#125;, "match_mapping_type": "string", "match": "*" &#125; &#125; ], "_all": &#123; "norms": false, "enabled": true &#125;, "properties": &#123; "@timestamp": &#123; "include_in_all": false, "type": "date" &#125;, "geoip": &#123; "dynamic": true, "properties": &#123; "ip": &#123; "type": "ip" &#125;, "latitude": &#123; "type": "half_float" &#125;, "location": &#123; "type": "geo_point" &#125;, "longitude": &#123; "type": "half_float" &#125; &#125; &#125;, "@version": &#123; "include_in_all": false, "type": "keyword" &#125; &#125; &#125; &#125;, "aliases": &#123;&#125; &#125;&#125; ② 使用默认模板，适合刚入门时快速验证使用，但不满足实际需求场景，此时可以在 Logstash 「配置文件」中「 output 」插件中指定自定义模板 覆盖默认模板1234567891011121314151617output &#123; if [type] == "knowledge" &#123; elasticsearch &#123; hosts =&gt; ["localhost:9200"] index =&gt; "yb_knowledge" document_id =&gt; "%&#123;id&#125;" template_overwrite =&gt; true template =&gt; "/usr/local/logstash/template/yb_knowledge.json" template_name =&gt; "yb_knowledge" &#125; &#125; stdout &#123; # JSON格式输出 codec =&gt; json_lines &#125;&#125; 配置项 说明 template_overwrite 是否覆盖默认模板 template 自定义模板文件路径 template_name 自定义模板名 注意事项： 如果不指定「 template_name 」则会永久覆盖默认的「 logstash 」模板，后续即使删除了自定义模板文件，在使用默认模板的情况下创建的索引还是使用先前自定义模板的配置。所以使用自定义模板时建议指定「 template_name 」防止出现一些难以察觉的问题。 如果不小心覆盖了默认模板，需要重置默认模板则执行以下命令后重启 Logstash。 1curl -XDELETE 'http://localhost:9200/_template/logstash' ES 会按照一定的规则来尝试自动 merge 多个都匹配上了的模板规则，最终运用到索引上。所以如果某些自定义模板不再使用记得使用上述命令及时删除，避免新旧版本的模板规则同时作用在索引上引发问题。 例：「 t1 」为旧模板，「 t2 」为新模板，它们的匹配规则一致，唯一的区别是「 t2 」删除了其中一个字段的规则，此时如果「 t1 」模板不删除则新建的索引还是会应用已删除的那条规则。 模板是可以设置 order 参数的，默认的 order 值就是 0。order 值越大，在 merge 模板规则的时候优先级越高。这也是解决新旧版本同一条模板规则冲突的一个解决办法。 ③ 自定义模板中设置索引别名，增加「 aliases 」配置项，如 yb_knowledge =&gt; knowledge12345"template": "yb_knowledge",...省略中间部分..."aliases": &#123; "knowledge": &#123;&#125;&#125; 6.4 Logstash 多个配置文件里的 input 、filter 、 output 是否相互独立？不独立；Logstash 读取多个配置文件只是简单的将所有配置文件整合到了一起。如果要彼此独立，可以通过 type 或 tags 区分，然后在 output 配置中用 if 语句判断一下 6.5 如何不停机重建索引？① 首先新建新索引「 v2 」② 其次将源索引「 v1 」的数据导入新索引「 v2 」中③ 然后设置索引别名（删除源索引「 v1 」别名，添加新索引「 v2 」别名）④ 之后修改 Logstash 配置文件中 output 的 index 值为新索引「 v2 」 注：前提是 Logstash 启动时指定config.reload.automatic设置项开启配置文件自动重载 ⑤ 再次执行步骤二增量同步源索引 v1中已修改但没同步到新索引「 v2 」中的数据⑥ 最后删除源索引「 v1 」]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建 ES 搜索服务（一）基本概念及环境搭建]]></title>
    <url>%2F2018%2F12%2F26%2Felasticsearch-1%2F</url>
    <content type="text"><![CDATA[一、前言本系列文章最终目标是为了快速搭建一个简易可用的搜索服务。方案并不一定是最优，但实现难度较低。 二、背景近期公司在重构老系统，需求是要求知识库支持全文检索。我们知道普通的数据库 like 方式效果及性能都不好，所以另寻出路，确定通过 Elasticsearch (下文简称「 ES 」)搜索引擎实现。 三、技术选型因公司之前购买了阿里云的ES服务且版本为 5.5.3 ，下文选用的技术框架均基于此版本。 ① Elasticsearch 5.5.3 一个基于Lucene的搜索服务器，提供了分布式的全文搜索引擎 ② Logstash 5.5.3 开源的服务器端数据处理管道 ③ Kibana 5.5.3 开源的分析和可视化平台 ④ Spring Boot 2.0.4 四、系统环境 Linux Centos 7.3 JDK 1.8 五、基本概念5.1 集群（ cluster ）集群是由一个或者多个拥有相同 cluster.name 配置的节点组成，共同承担数据和负载压力，当节点数量发生变化时集群将会重新平均分布所有数据。 5.2 节点（ node ）一个运行中的 ES 实例称为一个节点 主节点负责管理集群范围内的所有变更，例如增加/删除索引，或者增加/删除节点等，且不需要涉及到文档级别的变更和搜索等操作 任何节点都能成为主节点 当集群只有一个主节点，即使流量增加也不会成为瓶颈 5.3 索引（ index ） 名词；类似于传统关系数据库中的一个数据库 动词；索引一个文档就是存储一个文档到一个索引(名词)中以便它可以被检索和查询到。类似于 SQL 语句中的 INSERT 关键词 倒排索引；类似于传统关系型数据库中的索引概念，可以提升数据检索速度 5.4 类型（ type ）一个索引包含一个或多个 type ，相当于传统关系型数据库中的表 5.5 文档（ document ）相当于传统关系型数据库中的数据行 5.6 分片（ shards ） 是一个底层的「工作单元」，仅保存了全部数据的一部分 是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里 当集群规模扩大或者缩小时， ES 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里 分为「主分片」和「副本分片」 在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改；默认情况下会被分配「 5 」个主分片和「 1 」份副本（每个主分片拥有一个副本分片） 相同主分片的副本分片不会放在同一个节点 ① 主分片 ( Primary shard ) 索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量 ② 副本分片（ Replica shard ） 只是一个主分片的拷贝，作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务 六、环境搭建6.1 Elasticsearch6.1.1 安装步骤① 下载安装包：1$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.3.tar.gz ② 解压并移动到 local 目录下12$ tar -zxvf elasticsearch-5.5.3.tar.gz$ mv elasticsearch-5.5.3 /usr/local/elasticsearch ③ 修改 config 目录下的 elasticsearch.yml 文件1$ vim elasticsearch.yml 1234// 去掉行开头的 # 并重命名集群名，这里命名为 compasscluster.name: compass// 去掉行开头的 # 并重命名节点名，这里命名为 node-1node.name: node-1 ④ 进入 bin 目录启动 ES 并在后台运行1$ ./elasticsearch -d ⑤ 启动之后测试是否正常运行1$ curl 127.0.0.1:9200 返回结果：12345678910111213&#123; "name" : "node-1", "cluster_name" : "compass", "cluster_uuid" : "Zuj5FBMUTjuHQXlAHreGvA", "version" : &#123; "number" : "5.5.3", "build_hash" : "9305a5e", "build_date" : "2017-09-07T15:56:59.599Z", "build_snapshot" : false, "lucene_version" : "6.6.0" &#125;, "tagline" : "You Know, for Search"&#125; 6.1.2 如果提示「-bash: wget: command not found」则需要先安装 wget1$ yum -y install wget 6.1.3 ES 版本&gt; = 5.0.0 时，是不能用超级管理员运行的，此时需要切换到普通账号或者新建 ES 账号 解决办法： ① 新建用户组 elasticsearch1$ groupadd elasticsearch ② 新建用户并指定用户组1$ useradd -g elasticsearch elasticsearch ③ 修改 ES 目录所属者1$ chown -R elasticsearch:elasticsearch elasticsearch ④ 切换用户后再次启动1$ su elasticsearch 6.1.4 只能使用127.0.01或者localhost访问，使用ip地址无法访问？ 解决办法： ① 修改 elasticsearch.yml 中的「network.host」1network.host: 0.0.0.0 ② 重启 ES 出现如果如下报错，请依次按下面的步骤解决1234ERROR: [3] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2]: max number of threads [3818] for user [elasticsearch] is too low, increase to at least [4096][3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 每个进程最大同时打开文件数太小 修改 /etc/security/limits.conf 文件，增加如下配置，用户退出后重新登录生效 12* soft nofile 65536* hard nofile 65536 [2]: max number of threads [3818] for user [es] is too low, increase to at least [4096] 最大线程个数太低 同上修改 /etc/security/limits.conf 文件，增加如下配置，用户退出后重新登录生效 12* soft nproc 4096* hard nproc 4096 [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 一个进程能拥有的最多的内存区域 修改 /etc/sysctl.conf 文件，增加如下配置，执行命令「 sysctl -p 」生效1vm.max_map_count=262144 ③ 切换到 elasticsearch 用户并重启， curl 测试成功1234567891011121314[root@db-develop-01 ~]$ curl 192.168.1.192:9200&#123; "name" : "node-1", "cluster_name" : "compass", "cluster_uuid" : "mFL_a6WDTUaWbB4jKA8cWg", "version" : &#123; "number" : "5.5.3", "build_hash" : "9305a5e", "build_date" : "2017-09-07T15:56:59.599Z", "build_snapshot" : false, "lucene_version" : "6.6.0" &#125;, "tagline" : "You Know, for Search"&#125; 6.2 Logstash① 下载安装包：1$ wget https://artifacts.elastic.co/downloads/logstash/logstash-5.5.3.tar.gz ② 解压并移动到 local 目录下12$ tar -zxvf logstash-5.5.3.tar.gz$ mv logstash-5.5.3 /usr/local/logstash 6.3 Kibana① 下载安装包：1$ wget https://artifacts.elastic.co/downloads/kibana/kibana-5.5.3-linux-x86_64.tar.gz ② 解压并移动到 local 目录下12$ tar -zxvf kibana-5.5.3-linux-x86_64.tar.gz$ mv kibana-5.5.3-linux-x86_64 /usr/local/kibana ③ 修改 config 目录下的 kibana.yml 文件123456// 去掉当前行开头的 #server.port: 5601// 去掉当前行开头的#并将localhost修改为具体IPserver.host: &quot;192.168.1.191&quot;// 去掉当前行开头的#并将localhost修改为具体IPelasticsearch.url: &quot;http://192.168.1.191:9200&quot; ④ 启动 Kibana ，浏览器访问 http://192.168.1.191:56011$ ./kibana 6.4 elasticsearch-head 插件（浏览器版）① 「 Chrome 浏览器网上应用商店」或者「 Firefox 附加组件」搜索 elasticsearch head ② 安装插件后点击浏览器地址栏右侧「放大镜图标」，顶部输入框中的 localhost 修改为服务器地址即可查看 ES 服务状态 七、结语至此 ELK 环境搭建完毕，下一篇具体介绍如何实现基础搜索服务。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F09%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
